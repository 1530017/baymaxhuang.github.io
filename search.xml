<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Atomix源码分析：Raft Client的实现和与Server的交互]]></title>
      <url>%2F2017%2F11%2F13%2FAtomix%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%9ARaft%20Client%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%92%8C%E4%B8%8EServer%E7%9A%84%E4%BA%A4%E4%BA%92%2F</url>
      <content type="text"><![CDATA[Atomix是一个基于Raft协议的分布式协同框架，是ONOS分布式集群和分布式原语实现的基础，Atomix提供集群的管理，通信，领导选择，Key-Value存储，以及数据分片等功能。从Atomix 2.0开始，raft协议的实现Copycat已经集成到Atomix了，下面将结合Atomix 2.0对Atomix源码进行分析，从而深入理解Raft协议的原理和Atomix的工作机制。（更新中~） Atomix里的Raft实现主要包括raft client和raft server，raft server就是Raft里面实现数据一致性同步的节点，Raft里面的Leader，Candidate，Follower身份的确立和转换都是围绕raft server展开的,raft client通过raft session 与Raft状态机集群交互，从而完成状态机的查询，修改等操作。 注：Atomix 2.x在tests模块下新增了一个Raft测试文件RaftFuzzTest.java。这个文件包含了完整的raft client和raft server的建立过程，阅读这个文件的源码对了解和学习Atomix很有帮助！ 1. Raft client的实现Raft client的实现主要包括RaftClient，RaftProxy，RaftSession，包括Client与Server连接的建立，会话的管理，以及提交操作等功能。 1.1 创建RaftClientRaftClient提供了与Raft集群建立连接的接口，DefaultRaftClient是RaftClient的实现类，可以使用构造器创建RaftClient，DefaultRaftClient的类图如下所示： 在Atomix工程里面的RaftFuzzTest里有创建RaftClient的例子： 123456RaftClient client = RaftClient.newBuilder() .withMemberId(memberId) //1 .withProtocol(protocol) //2 .build(); client.connect(members.stream().map(RaftMember::memberId).collect(Collectors.toList())).join(); 其中，方法1设置该RaftClient的ID，一般用本机的IP地址表示，而方法2设置client与server的通信协议，该协议对象需要实现RaftClientProtocol接口。 创建好RaftClient后，使用RaftClient.connect与Raft cluster建立连接: 12345678910/*** Connects the client to Raft cluster via the provided server addresses.* &lt;p&gt;* The client will connect to servers in the cluster according to the pattern specified by the configured* &#123;@link CommunicationStrategy&#125;.** @param members A set of server addresses to which to connect.* @return A completable future to be completed once the client is registered.*/CompletableFuture&lt;RaftClient&gt; connect(Collection&lt;MemberId&gt; members); 由上面的注释可知该该raft client与raft cluster的哪一个成员建立连接，是根据CommunicationStrategy类进行配置的，而配置这CommunicationStrategy由RaftProxy来完成的。 PS: 注意这里虽然说是建立连接，但也只是做一些建立连接的初始化工作，正真的建立（如发送建立会话的请求）在RaftProxy创建完成后进行的。 1.2 创建RaftProxyRaftProxy提供了提交特定操作到raft cluster状态机的接口，主要包括invoke方法和addEventListener方法，RaftFuzzTest中给了RaftProxy的创建示例： 12345678910111213/*** Creates a test session.*/private RaftProxy createProxy(RaftClient client, ReadConsistency consistency) &#123; return client.newProxyBuilder() //1 .withName("test") //2 .withServiceType("test") .withReadConsistency(consistency) //3 .withCommunicationStrategy(COMMUNICATION_STRATEGY) //4 .build() //5 .open() .join();&#125; 上述代码方法1返回一个新的RaftProxy.Builder从而开始建立会话连接；方法2是设置该会话的名称；方法3设置状态机查询的一致性等级，有线性一致性，顺序一致性等，Raft协议中线性一致性的查询最终必须由Leader来处理；而方法4则设置该会话与Raft cluster的通信策略，可以指定该会话直接和Leader建立，也可让该会话随机和cluster中的某一个节点建立。更多的细节原理可以阅读ReadConsistency和CommunicationStrategy的文档注释。上面的代码将为一个raft client创建一个会话连接，可以重复上述步骤为该client建立多个到raft cluster的会话连接。需要注意的是，方法1中返回的RaftProxy.Builder是在DefaultRaftClient内实现的： 123456789101112131415/*** Default Raft session builder.*/private class SessionBuilder extends RaftProxy.Builder &#123;@Overridepublic RaftProxy build() &#123; // Create a client builder that uses the session manager to open a session. RaftProxyClient.Builder clientBuilder = new RaftProxyClient.Builder() &#123; @Override public CompletableFuture&lt;RaftProxyClient&gt; buildAsync() &#123; return sessionManager.openSession(name, serviceType, readConsistency, communicationStrategy, timeout); &#125; &#125; ....&#125; 通过注释可知，该Builder会建立一个会话连接，这是通过该Builder实现buildAsync方法并在buildAsync内部调用RaftProxyManager的openSession方法实现的,buildAsync最终由方法5调用。 1.3 创建会话连接Raft client和server所有会话的创建和管理由RaftProxyManager类实现。RaftProxyManager的构造函数如下:12345678910111213141516171819public RaftProxyManager(String clientId, MemberId memberId, RaftClientProtocol protocol, MemberSelectorManager selectorManager, ScheduledExecutorService threadPoolExecutor) &#123;this.clientId = checkNotNull(clientId, "clientId cannot be null");this.memberId = checkNotNull(memberId, "memberId cannot be null");this.protocol = checkNotNull(protocol, "protocol cannot be null");this.selectorManager = checkNotNull(selectorManager, "selectorManager cannot be null");this.log = ContextualLoggerFactory.getLogger(getClass(), LoggerContext.builder(RaftClient.class) .addValue(clientId) .build());this.connection = new RaftProxyConnection( protocol, selectorManager.createSelector(CommunicationStrategy.ANY), new ThreadPoolContext(threadPoolExecutor), LoggerContext.builder(RaftClient.class) .addValue(clientId) .build());this.threadPoolExecutor = checkNotNull(threadPoolExecutor, "threadPoolExecutor cannot be null"); &#125; 注意这里面构造了一个RaftProxyConnection对象，建立会话的open-session消息以及保持该会话连接的keep-alive消息的发送和接收都是由该对象完成的。传入的参数selectorManager.createSelector(CommunicationStrategy.ANY表示该connection是随机和cluster中的某一个成员建立的，后面的keep-alive请求也都会持续发往该成员节点并由该节点处理。笔者阅读了Raft server实现的相关代码，发现raft follower角色的成员也不直接处理open-session或keep-alive请求，而是将这个请求forward给leader处理，具体的逻辑可以参考RaftRole接口及其类的实现。需要注意的，client session信息都是以复制状态机的形式保存的，也就是说raft cluster中的每一个节点都保存有该session的信息，另外当leader处理一个open-session或keep-alive请求时，也会先更新follower的状态机信息（主要是该会话的时间戳），然后提交该更新到本地状态机。 RaftProxyManager类里的openSession方法调用RaftProxyConnection类的openSession方法发送一个open-session请求，返回的response结果中包含该session的sessionId，timeout等信息，然后使用keepAliveSessions方法发送该会话的keep-alive消息。 在RaftProxyManager类里面，keep-alive的发送和调度分别是由keepAliveSessions(long timeout)和scheduleKeepAlive(long timeout, long delta)方法完成的。注意这个timeout的值是根据OpenSessionResponse获得的，在LeaderRole中可以看到OpenSessionResponse的构造逻辑：1234567891011121314@Overridepublic CompletableFuture&lt;OpenSessionResponse&gt; onOpenSession(OpenSessionRequest request) &#123;final long term = raft.getTerm();final long timestamp = System.currentTimeMillis();// If the client submitted a session timeout, use the client's timeout, otherwise use the configured// default server session timeout.final long timeout;if (request.timeout() != 0) &#123; timeout = request.timeout();&#125; else &#123; timeout = raft.getSessionTimeout().toMillis();&#125;...... 在使用RaftProxy.Builder构造RaftProxy时可以设置该session的timeout，如果没有设定，timeout默认为0，那么Leader也将通过request-response返回一个timeout，这个timeout在RaftContext类中被默认设置为5000ms。 另外scheduleKeepAlive(long timeout, long delta)方法中的delta参数表示从发送一个keep-alive请求到接收到该请求响应的时间间隔，keep-alive循环调度的方法实现如下：12345678910111213141516 /*** Schedules a keep-alive request.*/private synchronized void scheduleKeepAlive(long timeout, long delta) &#123;ScheduledFuture&lt;?&gt; keepAliveFuture = keepAliveFutures.remove(timeout);if (keepAliveFuture != null) &#123; keepAliveFuture.cancel(false);&#125;// Schedule the keep alive for 3/4 the timeout minus the delta from the last keep-alive request.keepAliveFutures.put(timeout, threadPoolExecutor.schedule(() -&gt; &#123; if (open.get()) &#123; keepAliveSessions(timeout); &#125;&#125;, Math.max(Math.max((long)(timeout * .75) - delta, timeout - 2500 - delta), 0), TimeUnit.MILLISECONDS));&#125; 上面的delta表示从发送keep-alive请求到获得该请求响应的时间间隔，一般该时间很短（2~4ms），因此若timeout设置成6000ms，那么keep-alive消息的发送间隔为4500ms左右。 2. Raft client和raft server的交互2.1 Raft client和raft server间消息的发送和回传由于Atomix中使用了很多函数式编程以及回调处理，很多的代码调动关系不是很直观，下面将以RaftFuzzTest的实现为例介绍Keep-Alive消息的发送和处理流程。 首先需要了解的是RaftFuzzTest中使用的RaftClientProtocol和RaftServerProtocol都是基于MessagingService消息处理接口实现的。该消息处理接口会区分每一种消息的类型，同时也需要给不同的消息类型注册不同的处理方法，当收到一种特定类型的消息时，就会回调对应的处理方法。 如前面所述，将使用RaftProxyConnection类的keepAlive方法开始发送keep-alive请求： 123456789101112131415/*** Sends a keep alive request to the given node.** @param request the request to send* @return a future to be completed with the response*/public CompletableFuture&lt;KeepAliveResponse&gt; keepAlive(KeepAliveRequest request) &#123;CompletableFuture&lt;KeepAliveResponse&gt; future = new CompletableFuture&lt;&gt;();if (context.isCurrentContext()) &#123; sendRequest(request, protocol::keepAlive, next(), future);&#125; else &#123; context.execute(() -&gt; sendRequest(request, protocol::keepAlive, next(), future));&#125;return future;&#125; 这里的protocol是一个实现了RaftClientProtocol接口对象，负责消息的发送，该对象在创建RaftClient时注册进来的。而next()则返回接收该request请求的目的成员ID，然后sendRequest将调用RaftClientProtocol的keepAlive方法发送该keep-alive请求，RaftFuzzTest中使用的RaftClientProtocol接口是在RaftClientMessagingProtocol类中实现： 12345678910111213@Overridepublic CompletableFuture&lt;KeepAliveResponse&gt; keepAlive(MemberId memberId, KeepAliveRequest request) &#123; return sendAndReceive(memberId, "keep-alive", request);&#125;protected &lt;T, U&gt; CompletableFuture&lt;U&gt; sendAndReceive(MemberId memberId, String type, T request) &#123; Endpoint endpoint = endpoint(memberId); if (endpoint == null) &#123; return Futures.exceptionalFuture(new ConnectException()); &#125; return messagingService.sendAndReceive(endpoint, type, serializer.encode(request)) .thenApply(serializer::decode);&#125; 虽然上面的回调直接返回了处理后的结果，那么这个请求在实际中是怎么处理和返回的呢？事实上，上面的sendAndReceive(memberId, &quot;keep-alive&quot;, request)方法使用了一个很重要的参数，即这个请求的消息类型是：”keep-alive”，而raft server节点会根据请求的类型调用对应的处理方法。RaftServerProtocol接口中有一个注册处理keep-alive消息的handler的方法： 123456/*** Registers a keep alive request callback.** @param handler the open session request handler to register*/void registerKeepAliveHandler(Function&lt;KeepAliveRequest, CompletableFuture&lt;KeepAliveResponse&gt;&gt; handler); RaftFuzzTest使用的RaftServerMessagingProtocol是一个实现了RaftServerProtocol接口的类，在这个类里面，注册处理keep-alive消息的Handler的方法实现如下： 1234567891011121314151617@Overridepublic void registerKeepAliveHandler(Function&lt;KeepAliveRequest, CompletableFuture&lt;KeepAliveResponse&gt;&gt; handler) &#123; registerHandler("keep-alive", handler);&#125;protected &lt;T, U&gt; void registerHandler(String type, Function&lt;T, CompletableFuture&lt;U&gt;&gt; handler) &#123;messagingService.registerHandler(type, (e, p) -&gt; &#123; CompletableFuture&lt;byte[]&gt; future = new CompletableFuture&lt;&gt;(); handler.apply(serializer.decode(p)).whenComplete((result, error) -&gt; &#123; //1 if (error == null) &#123; future.complete(serializer.encode(result)); //2 &#125; else &#123; future.completeExceptionally(error); &#125; &#125;); return future; //3&#125;);&#125; 由此可以看出，一个特定类型消息的处理方法最终会注册到messagingService里面，方法1调用了Handler处理方法的，而方法2则等待处理结果的返回，方法3则返回一个异步执行的结构。因此当MessagingService收到一个特定类型的消息时，就会调用已注册的对应该消息的处理方法，从而完成消息的处理，MessagingService会回传该Handler返回的结果。 上面处理keep-alive请求的Handler的注册的过程是在RaftContext类里实现的，这也是一个非常重要的类，前面也有提及，raft状态机状态的管理就是通过这个类实现的。注册Handler的部分代码如下所示： 123456789 /*** Registers server handlers on the configured protocol.*/ private void registerHandlers(RaftServerProtocol protocol) &#123; protocol.registerOpenSessionHandler(request -&gt; runOnContext(() -&gt; role.onOpenSession(request))); protocol.registerCloseSessionHandler(request -&gt; runOnContext(() -&gt; role.onCloseSession(request))); protocol.registerKeepAliveHandler(request -&gt; runOnContext(() -&gt; role.onKeepAlive(request))); ...... &#125; 因此，当raft server收到一个“keep-alive”类型的请求时，就会调用role.onKeepAlive(request))方法，并返回一个处理后的结果，即返回一个CompletableFuture&lt;KeepAliveResponse&gt;&gt;类型的值。 由上面的分析可知，Atomix里面消息的处理流程的核心思想就是注册和回调，同时使用CompletableFuture作为异步计算的结果，提高程序的运行效率。 2.2 Client对状态机的操作Client对状态机的操作包括写和读，分别用Command和Query来表示。Command操作会是状态机发生转移，需要通过leader写log，Query操作可以根据一致性等级进行操作，若需实现线性一致性，需要leader的处理。 2.2.1 Command操作参考： Atomix ONOS cluster分布式数据存储和东西向通信]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用CBench测试控制器性能及控制器性能调优总结]]></title>
      <url>%2F2017%2F06%2F26%2F%E4%BD%BF%E7%94%A8CBench%E6%B5%8B%E8%AF%95%E6%8E%A7%E5%88%B6%E5%99%A8%E6%80%A7%E8%83%BD%E5%8F%8A%E6%8E%A7%E5%88%B6%E5%99%A8%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[CBench是一个基于OpenFlow协议的控制器性能测试工具，由于笔者在控制器开发过程需要测试控制器的性能，因而研究了CBench的相关代码，并做了一些开发和优化。下面是笔者使用CBench测试控制器性能及控制器性能调优总结。 1. CBench原理及其使用1.1 CBench原理CBench通过伪造交换机（fakeswitch）与控制器握手，每个交换机与控制器建立一个socket连接，使用poll方式实现I/O多路复用，整个程序是一个单线程程序。CBench可以工作在以下两种模式： Lantency模式 每次发送一个PacketIn消息，并统计回应，不断重复这样的步骤，统计1秒（默认是1秒）内控制器响应的次数。 Throughput模式 每次用PacketIn消息填满消息队列（outbuf，长度是65536），然后将该消息队列的消息由socket发往控制器，并统计回应，重复这样的步骤，统计1秒（默认是1秒）内控制器响应的次数。 需要注意的是，CBench和控制器建立的是TCP连接，在通信带宽不受限的情况下，CBench在单位时间内能够发送的请求的个数，不仅和CBench自身性能有关，还和控制器的处理能力有关。当控制器处理能力受限时，TCP会自动调整接收窗口（rwnd）和拥塞控制窗口（cwnd）的大小，CBench发送请求的速率也会降低。 1.2 CBench的使用CBench的使用也很简单，下载源码直接编译就可以了。由于这个代码比较老旧，这个project在新版本的操作系统中编译可能会出现问题（亲测在Ubuntu 14.04系统编译可以通过，但在Ubuntu 16.04中编译就有问题）。不过CBench只是这个oflops的一个子模块，因此笔者重构了CBench部分的代码，从而使得CBench可以单独编译，见：重构后的CBench源码和使用, 该版本的代码可以很容易的使用cmake和gcc编译，并用与OpenFlow控制器的测试。另外，由于笔者在控制器开发过程中需要使用其它的南向协议，因而修改了CBench的协议栈相关的代码，见：源码。 2. CBench测试控制器性能笔者使用的是基于Java开发的控制器，因此Java虚拟机内存的分配对控制器性能的测试影响很大。同时为了避免带宽资源的限制，CBench和控制器都在同一机器上运行。参考： Single-node ONOS Cbench 3. 控制器性能调优笔者在要完成的是基于ONOS的POF控制器的性能测试。但在测试的过程中发现，基于ONOS的OpenFlow控制器的响应速率可以达到90w/s，而相同环境下基于ONOS的POF控制器的性能只有4w/s。于是笔者尝试使用Java程序的性能分析工具VisuaVM来分析程序的性能，关于VisualVM的使用，参考：使用 VisualVM 进行性能分析及调优。 下面是使用VisualVM观测到在测试过程中CPU和内存的使用情况： 从图中可以发现，限制控制器性能的主要还是CPU资源，于是进一步使用VisualVM测试了关键方法的耗时： 可以发现，大量CPU资源不是消耗在了与io相关的操作，而是消耗在了与io无关的object.toString方法。检查程序发现在与程序io相关的decode方法中使用了log.debug方法，而该方法虽然不会在正常模式下输出日志，但是该方法及其内部字符串拼接操作都会执行，造成大量的CPU资源浪费。下面一段简单的验证代码： 123456789int x = 0;log.info(&quot;test for inf, x: &#123;&#125;&quot;, x);log.debug(&quot;test for debug, x: &#123;&#125;&quot;, test());log.info(&quot;test for x: &#123;&#125;&quot;, x); int test() &#123; x = x + 1; return x;&#125; 以上日志的输出为： 12test for inf, x: 0test for x: 1 这个例子说明log.debug中的test函数也执行了，只是日志没有输出。这也提示我们使用log日志时一定要谨慎，避免使用没有必要日志输出！！！ 下面是去掉debug相关的日志方法后的关键方法耗时分析： 可以发现，现在CPU主要用于io相关的操作了，而测试结果也从4w/s上升到了130w/s。:) 另外，笔者也发现当请求或响应数据包的长度增加时，测试过程中控制器的Java虚拟机GC活动也会增加，造成测试的控制器性能下降，这在控制器测试或性能调优的过程中也是需要注意的。 4. 总结本文分析了CBench工作原理，介绍了CBench使用方法和一些需要注意的问题。另外，本文也从控制器测试的实战经验出发，介绍了Java程序的性能分析和调优方法，以飨读者。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kryo序列化及其在ONOS中的应用]]></title>
      <url>%2F2017%2F06%2F14%2FKryo%E5%BA%8F%E5%88%97%E5%8C%96%E5%8F%8A%E5%85%B6%E5%9C%A8ONOS%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
      <content type="text"><![CDATA[Kryo是一个快速高效的Java序列化框架，旨在提供快速、高效和易用的API。无论文件、数据库或网络数据Kryo都可以随时完成序列化。Kryo还可以执行自动深拷贝（克隆）、浅拷贝（克隆）。这是对象到对象的直接拷贝，而不是对象-&gt;字节-&gt;对象的拷贝。 1. Kryo的快速入门首先，建议使用maven的方式在pom.xml中添加Kryo依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.esotericsoftware&lt;/groupId&gt; &lt;artifactId&gt;kryo&lt;/artifactId&gt; &lt;version&gt;4.0.0&lt;/version&gt;&lt;/dependency&gt; 然后，使用下面的方式就能完成对象的序列化了： 12345678910Kryo kryo = new Kryo();// ...Output output = new Output(new FileOutputStream("file.bin"));SomeClass someObject = ...kryo.writeObject(output, someObject);output.close();// ...Input input = new Input(new FileInputStream("file.bin"));SomeClass someObject = kryo.readObject(input, SomeClass.class);input.close(); 2. 注册要序列化的类当事先没有注册要序列化的类时，Kryo会自动的注册所有要使用的类，但这会增加序列化的一些overhead，例如需要在序列化时添加完整的类名称信息。而且，这种自动注册方式会使得不同程序或线程对同样的类的注册顺序不一样，从而对同样的类的产生不一样的注册ID，这样不同程序或线程对同样的类的序列化和去序列化就会发生问题。 可以使用 kryo.setRegistrationRequired(true) 要求显示注册要序列化的类。这样如果类没有注册，在序列化过程中就会产生java.lang.IllegalArgumentException的异常： 12345Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: Class is not registered: kryo.test.ANote: To register this class use: kryo.register(kryo.test.A.class); at com.esotericsoftware.kryo.Kryo.getRegistration(Kryo.java:503) at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:557)...... 使用下面的方法注册要序列化的类： 123456Kryo kryo = new Kryo();kryo.register(SomeClass.class);// ...Output output = ...SomeClass someObject = ...kryo.writeObject(output, someObject); 在注册类的时候，Kryo会给每个类关联一个唯一的ID，不同的类的ID不一样，当在序列化类的对象时，Kryo只需保存这个类的ID信息，就可以识别序列化对象的类信息了。相对于保存完整的类名称信息，这种序列化方式能够提高效率。因此，不同程序或线程在对同样的对象信息序列化和去序列化时，要保证同样的类的注册ID是一样的。 当然，也可以指定类的注册ID信息： 1234Kryo kryo = new Kryo();kryo.register(SomeClass.class, 10);kryo.register(AnotherClass.class, 11);kryo.register(YetAnotherClass.class, 12); 3. 序列化器（serializer）对Java中的一些基本数据类型，如bood，short，int，char等，字符串类型String，基本数据类型的装箱类，Boolean，Short，Integer等，以及常见的集合类型，Kryo都有默认的序列化方式。参考Default serializers 用户可以在注册过程中添加指定的serializer： 123Kryo kryo = new Kryo();kryo.register(SomeClass.class, new SomeSerializer());kryo.register(AnotherClass.class, new AnotherSerializer()); 4. 多线程下使用KryoKryo不是线程安全的，每一个线程应该有自己的Kryo，Input，和Output实例。另外，在去序列化过程中使用byte[] Input时，这个byte[]数组会被修改并在去序列化完成后返回到初始状态。因此不同的线程不能同时使用相同的byte[] Input。 5. 池化Kryo实例由于Kryo实例的创建和初始化的代价很高，并且不同的线程需要独立的Kryo实例。因此，多线程环境下应该考虑池化Kryo实例，从而减少Kryo实例创建和初始化的开销，提高序列化的效率。 方法一：使用ThreadLocal建立Kryo实例： 123456789101112// Setup ThreadLocal of Kryo instancesprivate static final ThreadLocal&lt;Kryo&gt; kryos = new ThreadLocal&lt;Kryo&gt;() &#123; protected Kryo initialValue() &#123; Kryo kryo = new Kryo(); // configure kryo instance, customize settings return kryo; &#125;;&#125;;// Somewhere else, use KryoKryo k = kryos.get();... 使用ThreadLocal创建只能被一个线程读写的变量，不同线程可以同时使用一个ThreadLocal变量的引用，但它可访问的ThreadLocal变量保存的值是相互独立的。这里将Kryo实例保存在ThreadLocal变量中，不同线程使用get方法获得一个独立的Kryo实例，这样使非线程安全的Kryo对象变得线程安全。 FIXME：虽然这样做能够实现线程安全的Kryo对象，但由于每个线程获得的是与该线程相关的独立Kryo实例，因此并不能减少Kryo实例创建和初始化的开销？ 方法二：使用Kryo提供的KryoPool产生Kryo实例： 1234567891011121314151617181920212223import com.esotericsoftware.kryo.Kryo;import com.esotericsoftware.kryo.pool.*;KryoFactory factory = new KryoFactory() &#123; public Kryo create () &#123; Kryo kryo = new Kryo(); // configure kryo instance, customize settings return kryo; &#125;&#125;;// Build pool with SoftReferences enabled (optional)KryoPool pool = new KryoPool.Builder(factory).softReferences().build();Kryo kryo = pool.borrow();// do s.th. with kryo here, and afterwards release itpool.release(kryo);// or use a callback to work with kryo - no need to borrow/release,// that&apos;s done by `run`.String value = pool.run(new KryoCallback() &#123; public String execute(Kryo kryo) &#123; return kryo.readObject(input, String.class); &#125;&#125;); KryoPool将所有的Kryo实例保存在一个Queue中，查看Kryo源码可以发现该Queue是一个ConcurrentLinkedQueue，因此是线程安全的。同时，可以使用borrow和release方法租用和释放Kryo实例，减少Kryo实例创建和初始化的开销。 6. Kryo在ONOS中的应用ONOS使用Kryo序列化对象，使用一个KryoNamespace类来管理类的注册，Kryo类的池化，并提供序列化方法。 kryonamespaces实现KryoFactory, KryoPool接口，kryonamespaces类中有最重要的两个数据属性，一个是： 1private List&lt;Pair&lt;Class&lt;?&gt;, Serializer&lt;?&gt;&gt;&gt; types = new ArrayList&lt;&gt;(); 它保存注册的序列化的类和其对应的序列化器，当我们将类注册进kryonamespace时就是在向这个List里面添加pair。 另一个是： 1private int blockHeadId = INITIAL_ID; 当我们在注册需要序列化的类的时候该int类型的数据就会在原来的数据上加1。另外就是序列化实现的时候是将list类型的type改造成RegistrationBlock类之后再用list将其整块整块装进去，具体过程参考KryoNamespace.Builder。 kryonamespaces提供如下的序列化方法： 123456789101112131415161718192021222324252627/** * Serializes given object to byte array using Kryo instance in pool. * &lt;p&gt; * Note: Serialized bytes must be smaller than &#123;@link #MAX_BUFFER_SIZE&#125;. * * @param obj Object to serialize * @return serialized bytes */public byte[] serialize(final Object obj) &#123; return serialize(obj, DEFAULT_BUFFER_SIZE);&#125;/** * Serializes given object to byte array using Kryo instance in pool. * * @param obj Object to serialize * @param bufferSize maximum size of serialized bytes * @return serialized bytes */public byte[] serialize(final Object obj, final int bufferSize) &#123; Output out = new Output(bufferSize, MAX_BUFFER_SIZE); return pool.run(kryo -&gt; &#123; kryo.writeClassAndObject(out, obj); out.flush(); return out.toBytes(); &#125;);&#125; 可以看出，serialize最终使用kryo.writeClassAndObject方法完成对象的序列化。 参考： https://github.com/EsotericSoftware/kryo Kryo为什么比Hessian快 Java并发编程：深入剖析ThreadLocal]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ONOS cluster分布式数据存储和东西向通信]]></title>
      <url>%2F2017%2F02%2F15%2FONOS-cluster%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E5%92%8C%E4%B8%9C%E8%A5%BF%E5%90%91%E9%80%9A%E4%BF%A1%2F</url>
      <content type="text"><![CDATA[ONOS是一个分布式的控制器，为了提高数据的读写效率，采用自实现的基于In-Memory的Key-Value数据存储系统。针对实际的需要，不同的数据模型采用不同的数据一致性方法，即强一致性（strong consistency）和最终一致性（eventually consistency）。ONOS使用raft协议实现强一致性，使用anti-entropy（gossip）协议实现最终一致性。 1. ONOS系统架构演进ONOS当前的数据采用In-Memory方式存储和同步，其架构师Madan Jampani来自Amazon，是Amazon的Dynamo的核心架构师之一，07年就在业界发表过分布式存储论文Dynamo。另一位Jordan Halterman就是Raft协议的Java实现版CopyCat，分布式协同框架Atomix的作者。然而，最初的ONOS版本使用的是一些比较成熟的第三方的数据库存储系统。如ONOS的第一个样机使用Cassandra作为数据分布式数据存储系统，使用Zookeeper实现设备与ONOS的主从关系控制器，实现ONOS集群管理。为了提高ONOS的性能，ONOS正式发布的1.0版本采用的是embedded模式下的Hazelcast作为基于内存的分布式存储系统，embedded模式下的Hazelcast采用peer-to-peer的方式通信，每一个ONOS instance作为一个peer，ONOS的业务数据存储在用一个JVM中，从而提高ONOS cluster的性能。 然而，使用第三方库的风险是不可控的，尤其在第三方库版本升级或有bug时，这对于想要实现一个搞性能，高可靠的控制器来说是不可接受的，因此，ONOS在后面的版本中使用自研的基于raft协议的分布式存储系统。Raft协议比Paxo协议简单易懂，目前已经有很多语言的实现版本，ONOS使用的是基于Java实现的CopyCat版本。但ONOS没有直接使用CopyCat，而是使用了基于raft的分布式协同框架Atomix，该框架通过提供一些简单的原语接口来隐藏分布式系统中的复杂问题，如领导选择，并发控制，数据分片和复制等。 从ONOS系统架构演进的过程中，我们可以看出实现一个高性能，搞可靠的分布式系统架构并不容易，需要根据实际的业务特性付出很多尝试很创新。然而，利用已有的技术的方法快速实现一个original prototype也是一个很好的选择。 参考： ONOS高可用性和可扩展性实现初探 ONOS系统架构之高可用实现方案的演进 Hazelcast Consistency and Replication Model 2. ONOS数据存储的一致性模型在分布式数据存储系统中，数据的一致性模型分为两类，即强一致性和最终一致性： 强一致性(strong consistency)：多个进程或节点在任何时刻都能读取到相同的数据，当有节点要对数据更新时，各个节点要确认对更新的值达成一致后再更新相应的数据，ONOS使用RAFT协议实现强一致性。 最终一致性(eventual consistency)：多个进程或节点在相同的时刻可能对相同数据有不同的访问值，但经过一定时间后数据的更新会达成一致，ONOS使用事件乐观异步复制和anti-entropy(gossip)协议实现最终一致性。下面是最终一致性的实现方法： 何时使用强一致性和若一致性，这取决于系统对不同模型的一致性需求，同时要考虑实际一致性的可操作性。例如每个控制器都要有网络的全局拓扑信息，在很多情况下，拓扑信息是不变的，拓扑信息的变化是由于物理网络的变化，控制器只是拓扑信息的观察者，这在实现强一致性过程中需要很多代价，因此对于物理拓扑，ONOS使用最终一致性。事实上，传统的OSPF协议也是使用弱一致性快速收敛的。若控制器是数据变化的生产者，往往采用强一致性，如Intent下发，控制器到交换机的主从关系的维护。下面是ONOS中使用的一致性模型分类： 数据类型 一致性模型 Network Topology, Flow Stats 最终一致，低延迟读取 Flow Rules 乐观复制备份 Application, Intents, Resource Allocations 强一致性 为了隐藏数据存储的复杂性，ONOS提供了一些分布式原语（distributed primitive）来实现数据的强一致性和最终一致性存储，使用StorageService服务可以创建这些原语数据结构。如EventuallyConsistentMap&lt;K, V&gt;用来存贮一个最终一致性map，EventuallyConsistentMap直接在本地进行数据读写操作，有节点的map值发生更新时，ONOS会广播更新时间和更新的值，其它的节点会通过比较时间戳来更新map的值。另外，当有新节点加入或有节点的数据突然丢失时，ONOS使用anti-entropy(gossip)协议来确保数据的最终一致性。而ConsistentMap&lt;K, V&gt;是一个实现了强一致性的map，该map最终是通过Atomix框架的raft协议实现的。但需要注意的是，强一致性也有不同的等级，如线性一致性（linearizable consistency）, 可串化一致性（serializable consistency）, 顺序一致性（sequential consistency）。ConsistentMap实现的一致性模型是线性一致性地写和顺序一致性地读，也就是说，一个节点执行了写操作，那么这个写操作会立即在这个节点完成，即这个写操作对当前节点后面的读操作都是可见的（linearizable consistency）。ConsistentMap并不保证这个写操作对其它节点也立即可见，但其它节点会以相同的顺序读取到当前节点的更新（sequential consistency）。 需要注意的是，实现强一致性的代价是昂贵的，为了提高数据的读取效率，可以使用本地缓存ConsistentMap的方式来提高部分读操作（如get，containsKey等操作）的读取效率，相关代码在CachingAsyncConsistentMap中实现。构建ConsistentMap时可以使用withRelaxedReadConsistency方法设置使用本地缓存的方式读取map。 参考： Googlegroups: Using both RAFT and Anti-Entropy for consensus Googlegroups: Why Network Topology can be used an Eventual Consistency model in ONOS 3. ONOS集群数据分片为了提高数据的访问效率，ONOS数据采用分片式(partition or shard)存储，每一个partition有多个（默认是3个）member(ONOS node)， 又称为一个raft group或partition server，每个partition的多个member使用raft协议（atomix框架的copycat实现）来保证数据的一致性，ONOS使用client-server模型来实现对不同partition数据的访问。默认的，对于n个节点的集群，有n个3-node partition，具体看查看ClusterManager源码。每个partition的数据更新是串行的（保证一致性），不同的partition的数据可以并行更新（数据分片提高数据的访问效率），使用2PC协议实现数据跨分片更新事务。下面是数据的分片复制图示： raft使用复制状态机的方式实现数据的一致性，可容忍少部分节点的故障失效，因此若数据分片大小为3，那么最多可容忍一个节点的失效。需要注意的是可容忍失效的节点数目与数据分片的个数有关，而与ONOS节点个数没有直接关系。 关于数据分片的管理和同步，可以查看PartitionService, PartitionAdminService，PartitionManager，StoragePartition，StoragePartitionClient，StoragePartitionServer等接口和类，注意：StoragePartition与StoragePartitionClient和StoragePartitionServer是相互引用的关系！下面是PartitionManager中的一段代码： ps： 这一小段代码就用到了java8的几个重要特性，如lambda表达式，流式处理，方法引用等，很酷吧！:wink: 12345678910111213141516171819@Activatepublic void activate() &#123; eventDispatcher.addSink(PartitionEvent.class, listenerRegistry); currentClusterMetadata.set(metadataService.getClusterMetadata()); metadataService.addListener(metadataListener); currentClusterMetadata.get() .getPartitions() .forEach(partition -&gt; partitions.put(partition.getId(), new StoragePartition(partition, messagingService, clusterService, CatalystSerializers.getSerializer(), new File(System.getProperty("karaf.data") + "/partitions/" + partition.getId())))); CompletableFuture&lt;Void&gt; openFuture = CompletableFuture.allOf(partitions.values() .stream() .map(StoragePartition::open) .toArray(CompletableFuture[]::new)); openFuture.join(); log.info("Started"); 可以看出，这里根据当前当前集群中已经分配好的partition来创建对应的目录文件，从而保存相关的数据信息，数据保存在karaf运行目录下的data/partitions文件夹中，查看各个各个节点中的partition目录下的文件，发现该目录下的partitionId信息与用partitions -c查看的信息是一致的。 使用partitions命令查看当前节点存储的分片信息，使用partitions -c查看当前节点以client身份访问的所有分片信息，前者返回的是StoragePartitionServer的信息，后者返回的是StoragePartitionClient的信息，二者和Atomix的框架实现有关。事实上，一个ONOS节点保存有多个分片信息，但可能不是所有分片的信息，每个ONOS节点是所有分片的client，使用client-server访问每一个分片的数据。在onos-gen-partition中可以设置分片大小，即每个分片的member成员的个数，初始分片配置信息保存在config/cluster.json中，分片的过程在ClusterManager类中执行。 12345678910111213141516171819202122232425262728293031323334353637383940onos&gt; partitions ----------------------------------------------------------Name Term Members ----------------------------------------------------------1 1 192.168.109.192:9876 192.168.109.193:9876 192.168.109.194:9876 *----------------------------------------------------------4 1 192.168.109.192:9876 * 192.168.109.195:9876 192.168.109.196:9876 ----------------------------------------------------------5 1 192.168.109.192:9876 * 192.168.109.193:9876 192.168.109.196:9876 ----------------------------------------------------------onos&gt; partitions -c-------------------------------------------------------------------Name SessionId Status Servers-------------------------------------------------------------------1 22 ACTIVE 192.168.109.192:9876 192.168.109.193:9876 192.168.109.194:9876-------------------------------------------------------------------2 3 ACTIVE 192.168.109.193:9876 192.168.109.194:9876 192.168.109.195:9876-------------------------------------------------------------------3 11 ACTIVE 192.168.109.194:9876 192.168.109.195:9876 192.168.109.196:9876-------------------------------------------------------------------4 4 ACTIVE 192.168.109.192:9876 192.168.109.195:9876 192.168.109.196:9876-------------------------------------------------------------------5 22 ACTIVE 192.168.109.192:9876 192.168.109.193:9876 192.168.109.196:9876------------------------------------------------------------------- 其中，name表示PartitionId，term表示当前领导任期，member表示分片成员raft group），*表示当前分片成员的领导（leader）。 由于ONOS采用领导选举机制来同步信息，因而不用的ONOS实例间的信息交互可能是不对称的。 注： ONOS中还有一种work partition，用来把一些task（主要和intent相关）分配到特定的节点，每一个work partition用topic来标识，使用leadershipService选举获得work partition的leader，具体的代码在WorkPartitionManager类中实现。 4. ONOS分布式原语实现分析ONOS提供多种的分布式原来实现分布式的操作和存储，如领导原则（LeaderElector），全局原子ID（AtomicIdGenerator），Key-Value（ConsistentMap）存储等，StorageService服务提供统一创建分布式原语的接口，使用构造器模式创建分布式原语。ONOS中每一个基于Atomix框架和Raft协议实现的分布式原语都对应的了一状态机实例，不同的状态机实例通过原语的名称进行区分，这些状态机实例共享存储在的数据分片集合中。下面以LeaderElector为例（1.11.0-SNAPSHOT），介绍分布式原语的实现和创建流程。 LeadElector的实现分析 LeadElector是针对一个特定的topic，选举一个leader，LeadElector是AsyncLeaderElector异步执行完成后的结果（即CompletableFuture.get方法返回的值），ONOS中的所有的分布式原语底层都是基于CompletableFuture异步实现的。需要注意的是，LeadElector实现的选举与raft算法里面的选举规则是不一样的，通过AsyncLeaderElector接口的注释可以发现，Atomix是通过FIFO的方式控制对一个topic标识的资源的访问来实现领导选举的。即当使用CompletableFuture&lt;Leadership&gt; run(String topic, NodeId nodeId)完成一次领导选举时，就会将该nodeId加入到该topic标识的队列中，所有队列中的节点都是该topic的Candidate，而队列头部的元素就是该topic的leader。ONOS中org.onosproject.store.primitives.resources.impl包下的AtomixLeaderElector类是AsyncLeaderElector底层实现，而LeaderElector对应的状态机操作在AtomixLeaderElectorService类中实现。事实上，每一个基于Atomix实现的原语都有一个AtomixXXX和AtomixXXXService的实现类。例如，AtomixLeaderElector类中的领导选举run方法的代码实现如下: 12345@Overridepublic CompletableFuture&lt;Leadership&gt; run(String topic, NodeId nodeId) &#123; return proxy.&lt;Run, Leadership&gt;invoke(RUN, SERIALIZER::encode, new Run(topic, nodeId), SERIALIZER::decode) .whenComplete((r, e) -&gt; cache.invalidate(topic));&#125; 该方法通过一个RaftProxy与Raft状态机进行交互，RUN就是这次操作的类型，代表的是一次写入操作，该状态机操作是通过AtomixLeaderElectorService类中的run方法实现的，返回的是一个Leadership类型的对象。 1234567891011121314151617181920212223242526272829303132/*** Applies an &#123;@link AtomixLeaderElectorOperations.Run&#125; commit.* @param commit commit entry* @return topic leader. If no previous leader existed this is the node that just entered the race.*/public Leadership run(Commit&lt;? extends Run&gt; commit) &#123; try &#123; String topic = commit.value().topic(); Leadership oldLeadership = leadership(topic); Registration registration = new Registration(commit.value().nodeId(), commit.session().sessionId().id()); elections.compute(topic, (k, v) -&gt; &#123; if (v == null) &#123; return new ElectionState(registration, termCounter(topic)::incrementAndGet); &#125; else &#123; if (!v.isDuplicate(registration)) &#123; return new ElectionState(v).addRegistration(registration, termCounter(topic)::incrementAndGet); &#125; else &#123; return v; &#125; &#125; &#125;); Leadership newLeadership = leadership(topic); if (!Objects.equal(oldLeadership, newLeadership)) &#123; notifyLeadershipChange(oldLeadership, newLeadership); &#125; return newLeadership; &#125; catch (Exception e) &#123; logger().error("State machine operation failed", e); throw Throwables.propagate(e); &#125;&#125; LeadElector的创建流程 LeadElector是LeadershipService实现的基础，在DistributedLeadershipStore类中，一个LeadElector实例的创建方法如下： 1234leaderElector = storageService.leaderElectorBuilder() //1 .withName("onos-leadership-elections") //2 .build() //3 .asLeaderElector(); //4 其中，1方法在StorageManager类中实现，返回的是DefaultLeaderElectorBuilder类型，DefaultLeaderElectorBuilder传入的参数是实现了DistributedPrimitiveCreator接口的FederatedDistributedPrimitiveCreator类型的实例，该实例在StorageManager中初始化： 12345678910@Activatepublic void activate() &#123; Map&lt;PartitionId, DistributedPrimitiveCreator&gt; partitionMap = Maps.newHashMap(); partitionService.getAllPartitionIds().stream() .filter(id -&gt; !id.equals(PartitionId.from(0))) .forEach(id -&gt; partitionMap.put(id, partitionService.getDistributedPrimitiveCreator(id))); federatedPrimitiveCreator = new FederatedDistributedPrimitiveCreator(partitionMap); transactionManager = new TransactionManager(this, partitionService); log.info("Started");&#125; 3方法将通过FederatedDistributedPrimitiveCreator.newAsyncLeaderElector方法创建一个AsyncLeaderElector，FederatedDistributedPrimitiveCreator.newAsyncLeaderElector方法实现如下： 123456789101112@Overridepublic AsyncLeaderElector newAsyncLeaderElector(String name, long leaderTimeout, TimeUnit timeUnit) &#123; checkNotNull(name); Map&lt;PartitionId, AsyncLeaderElector&gt; leaderElectors = Maps.transformValues(members, partition -&gt; partition.newAsyncLeaderElector(name, leaderTimeout, timeUnit)); Hasher&lt;String&gt; hasher = topic -&gt; &#123; int hashCode = Hashing.sha256().hashString(topic, Charsets.UTF_8).asInt(); return sortedMemberPartitionIds.get(Math.abs(hashCode) % members.size()); &#125;; return new PartitionedAsyncLeaderElector(name, leaderElectors, hasher);&#125; 其中members表示的是一个Map&lt;PartitionId, DistributedPrimitiveCreator&gt;类型的partitionMap，通过上面的代码片段可知该信息通过partitionService获得。由于ONOS对数据进行分片存储，分布式原语会在每一个partition上都创建一个实例。因此每一个partition都有一个DistributedPrimitiveCreator接口的实现，StoragePartitionClient负责该接口的最终实现，然后各个partition根据StoragePartitionClient.newAsyncLeaderElector方法创建一个AsyncLeaderElector实例，通过下面的代码片段可知AsyncLeaderElector最终是通过AtomixLeaderElector实现的： 123456789101112131415@Overridepublic AsyncLeaderElector newAsyncLeaderElector(String name) &#123; AtomixLeaderElector leaderElector = new AtomixLeaderElector(client.newProxyBuilder() .withName(name) .withServiceType(DistributedPrimitive.Type.LEADER_ELECTOR.name()) .withReadConsistency(ReadConsistency.LINEARIZABLE) .withCommunicationStrategy(CommunicationStrategy.LEADER) .withTimeout(Duration.ofSeconds(5)) //5 .withMaxRetries(5) .build() .open() .join()); leaderElector.setupCache().join(); return leaderElector;&#125; 注意上面代码中的5方法设置该原语实例（client）与状态机会话（RaftSession）的timeout，即当一个client超过timeout指定的时间（5s）未与状态机有heartbeat交互时，该会话就会结束，并触发AtomixLeaderElectorService中的onExpire和onClose方法。上述代码返回一个AtomixLeaderElector实例，最后不同分片的AtomixLeaderElector实例封装在一个实现了AsyncLeaderElector接口的PartitionedAsyncLeaderElector对象中，以run方法为例，可知PartitionedAsyncLeaderElector会更据topic和hash函数，找到对应的partion中的AtomixLeaderElector实例，并执行AtomixLeaderElector.run方法： 123456789101112@Overridepublic CompletableFuture&lt;Leadership&gt; run(String topic, NodeId nodeId) &#123; return getLeaderElector(topic).run(topic, nodeId);&#125;/** * Returns the leaderElector (partition) to which the specified topic maps. * @param topic topic name * @return AsyncLeaderElector to which topic maps */private AsyncLeaderElector getLeaderElector(String topic) &#123; return partitions.get(topicHasher.hash(topic));&#125; 另外，2方法设置该原语实例的名称，不同的原语实例需要使用不同的名称进行标记；4方法返回一个异步计算完成后的LeaderElector，即一个DefaultLeaderElector类型的实例。 5. ONOS intra-clusters东西向通信ONOS集群内的多个instance间通过TCP连接建立通信(目的端口是9876)，包括Raft，Anti-entropy，Heatbeat以及其它的数据同步信息，ONOS通过数据包中的metadata来区分不同作用的数据信息。在任何两个ONOS实例间，可以同时建立多个TCP连接通信，这些TCP连接在需要时建立，若这些TCP连接空闲超过1min，TCP连接会中断。通过查看ControllerNode的代码实现，可以发现默认的9876端口信息： ONOS基于Netty实现了一个异步的东西向通信消息服务接口（MessagingService），所有的东西通信都使用了这个消息服务接口，该消息接口是基于回调的思想实现的，MessagingService接口定义如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/**/** * Interface for low level messaging primitives. */public interface MessagingService &#123; /** * Sends a message asynchronously to the specified communication end point. * The message is specified using the type and payload. * @param ep end point to send the message to. * @param type type of message. * @param payload message payload bytes. * @return future that is completed when the message is sent */ CompletableFuture&lt;Void&gt; sendAsync(Endpoint ep, String type, byte[] payload); /** * Sends a message asynchronously and expects a response. * @param ep end point to send the message to. * @param type type of message. * @param payload message payload. * @return a response future */ CompletableFuture&lt;byte[]&gt; sendAndReceive(Endpoint ep, String type, byte[] payload); /** * Sends a message synchronously and expects a response. * @param ep end point to send the message to. * @param type type of message. * @param payload message payload. * @param executor executor over which any follow up actions after completion will be executed. * @return a response future */ CompletableFuture&lt;byte[]&gt; sendAndReceive(Endpoint ep, String type, byte[] payload, Executor executor); /** * Registers a new message handler for message type. * @param type message type. * @param handler message handler * @param executor executor to use for running message handler logic. */ void registerHandler(String type, BiConsumer&lt;Endpoint, byte[]&gt; handler, Executor executor); /** * Registers a new message handler for message type. * @param type message type. * @param handler message handler * @param executor executor to use for running message handler logic. */ void registerHandler(String type, BiFunction&lt;Endpoint, byte[], byte[]&gt; handler, Executor executor); /** * Registers a new message handler for message type. * @param type message type. * @param handler message handler */ void registerHandler(String type, BiFunction&lt;Endpoint, byte[], CompletableFuture&lt;byte[]&gt;&gt; handler); /** * Unregister current handler, if one exists for message type. * @param type message type */ void unregisterHandler(String type);&#125; 上面的消息服务接口中的每一个方法都有一个String type类型参数，表示的是该消息的类型。当消息到达Endpoint时，MessagingService会根据registerHandler注册的方法调用对应消息类型的处理方法，即message handler，从而完成消息的处理。 同时，为了方便使用东西向通信服务，ONOS又提供了一个集群通信服务服务接口（ClusterCommunicationService）,通过使用该服务，可以很容易的实现东西数据的传输和处理。很多的最终一致性store都使用了ClusterCommunicationService，如ECDeviceStore，ECLinkStore，DistributedFlowRuleStore等，同时EventuallyConsistentMapImpl中的anti-entropy的实现也都使用了该服务。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Flow Rule Subsystem简要分析]]></title>
      <url>%2F2017%2F01%2F15%2FFlow-Rule-Subsystem%E7%AE%80%E8%A6%81%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[Flow Rule Subsystem实现Flow rule的管理，存储和同步，用户可通过Flow Rule Subsystem提供的北向API（FlowRuleService）查询，下发和删除Flow rule。下面将结合Flow Rule Subsystem的代码，并以OpenFlow为例，简要分析Flow Rule Subsystem的实现过程，希望以此抛砖引玉。 分析Flow Rule Subsystem之前，我们需要对ONOS的子系统结构（Subsystem Structure）和事件（Event）机制有比较好的了解，参考ONOS子系统结构和事件调度处理机制 Flow Rule Subsystem分析在ONOS Core层，Flow Rule Subsystem的实现主要包括FlowRuleManager和DistributedFlowRuleStore这两个类，FlowRuleManager负责北向和南向接口的实现（FlowRuleService，FlowProviderService，FlowRuleProviderService等），是子系统的中枢，而DistributedFlowRuleStore负责数据的存储同步，是分布式实现的核心。下面是这两个类的UML图， FlowRuleManger类结构图： DistributedFlowRuleStore类结构图： 下面将以FlowRuleService方法applyFlowRules实现过程简要分析Flow Rule子系统。 每一个flowRule被封装成一个FlowRuleOperation，不同flowRule的集合被封装成一个FlowRuleOperations，然后调用apply方法。看代码注释，FlowRuleOperations是被分解成不同stage的FlowRuleOperation的集合，每一个stage是一组FlowRuleOperation的集合，不同stage的FlowRuleOperation集合保存在list中： 12345678910111213141516171819202122/*** A batch of flow rule operations that are broken into stages.* TODO move this up to parent's package*/public class FlowRuleOperations &#123; private final List&lt;Set&lt;FlowRuleOperation&gt;&gt; stages; private final FlowRuleOperationsContext callback; private FlowRuleOperations(List&lt;Set&lt;FlowRuleOperation&gt;&gt; stages, FlowRuleOperationsContext cb) &#123; this.stages = stages; this.callback = cb; &#125; // kryo-constructor protected FlowRuleOperations() &#123; this.stages = Lists.newArrayList(); this.callback = null; &#125; ......&#125; ONOS使用多线程的方式下发流表，但保证不同stage间FlowRuleOperation的下发是有顺序的，例如要使flowRule1在flowRule2之前下发完成，可以使用如下的方式构造不同stage的FlowRuleOperation： 12345FlowRuleOperations.Builder ops = FlowRuleOperations.builder();ops.add(flowRule1);ops.newStage();ops.add(flowRule2);flowRuleService.apply(ops.build()); apply方法中，将FlowRuleOperations放到一个线程容量为32的线程池中处理： 12345678......protected ExecutorService operationsService = Executors.newFixedThreadPool(32, groupedThreads("onos/Flowservice", "operations-%d", log));......public void apply(FlowRuleOperations ops) &#123; checkPermission(FlowRULE_WRITE); operationsService.execute(new FlowOperationsProcessor(ops));&#125; 下面是FlowOperationsProcessor类的代码，熟悉Java多线程编程的应该知道，新建的线程会运行run()方法，而FlowOperationsProcessor中的run方法调用了process方法处理FlowRuleOperation。这里使用了一个Multimap (Multimap perDeviceBatches) 来保存要下发到每个Device的Flow Rules的集合，每个Flow Rule被封装成一个FlowRuleBatchEntry类型的对象，保存在perDeviceBatches中。这样就以Device为单位将所有的FLow Rules进行归类，然后针对不同的Device逐个下发FlowRuleBatchOperation（就是一组待下发的Flow Rules集合）。这个类中，还有一个重要的属性pendingDevices，用来保存所有待下发Flow Rule的DeviceId的集合。当一个Device的FlowRuleBatchOperation下发完成后，该Device的DeviceId也会从pendingDevices移除，这个操作在satisfy方法中实现。并且当pendingDevices为空，即该stage的所有FlowRuleOperation下发完成后，就会调用operationsService.execute(this)进入下一个stage。从run方法可以看出，若所有的stages已经完成，并且没有出现过失败记录，那么就会回调FlowRuleOperations的onSuccess方法，通知应用程序所有的Flow Rules已经成功下发。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162private class FlowOperationsProcessor implements Runnable &#123; // Immutable private final FlowRuleOperations fops; // Mutable private final List&lt;Set&lt;FlowRuleOperation&gt;&gt; stages; private final Set&lt;DeviceId&gt; pendingDevices = new HashSet&lt;&gt;(); private boolean hasFailed = false; FlowOperationsProcessor(FlowRuleOperations ops) &#123; this.stages = Lists.newArrayList(ops.stages()); this.fops = ops; &#125; @Override public synchronized void run() &#123; if (!stages.isEmpty()) &#123; process(stages.remove(0)); &#125; else if (!hasFailed) &#123; fops.callback().onSuccess(fops); &#125; &#125; private void process(Set&lt;FlowRuleOperation&gt; ops) &#123; Multimap&lt;DeviceId, FlowRuleBatchEntry&gt; perDeviceBatches = ArrayListMultimap.create(); for (FlowRuleOperation op : ops) &#123; perDeviceBatches.put(op.rule().deviceId(), new FlowRuleBatchEntry(mapOperationType(op.type()), op.rule())); &#125; pendingDevices.addAll(perDeviceBatches.keySet()); for (DeviceId deviceId : perDeviceBatches.keySet()) &#123; long id = idGenerator.getNewId(); final FlowRuleBatchOperation b = new FlowRuleBatchOperation(perDeviceBatches.get(deviceId), deviceId, id); pendingFlowOperations.put(id, this); log.info("begin install flow rules to device &#123;&#125; with size &#123;&#125;", deviceId, b.getOperations().size()); deviceInstallers.execute(() -&gt; store.storeBatch(b)); &#125; &#125; synchronized void satisfy(DeviceId devId) &#123; pendingDevices.remove(devId); if (pendingDevices.isEmpty()) &#123; operationsService.execute(this); &#125; &#125; synchronized void fail(DeviceId devId, Set&lt;? extends FlowRule&gt; failures) &#123; hasFailed = true; pendingDevices.remove(devId); if (pendingDevices.isEmpty()) &#123; operationsService.execute(this); &#125; FlowRuleOperations.Builder failedOpsBuilder = FlowRuleOperations.builder(); failures.forEach(failedOpsBuilder::add); fops.callback().onError(failedOpsBuilder.build()); &#125;&#125; 正如在1.1节中介绍的那样，Manager有关数据信息的操作都会通过store来完成。这里，通过调用store.storeBatch将Flow rule信息添加到FlowRuleStore中。store.storeBatch也是在一个新的线程池中处理的,deviceInstallers的声明如下： 12protected ExecutorService deviceInstallers = Executors.newFixedThreadPool(32, groupedThreads("onos/Flowservice", "device-installer-%d", log)); storeBatch具体的实现细节比较复杂，如要判断FlowRuleBatchOperation的设备是否有对应的master控制器节点，以及当前的节点是否就是master控制器节点，这是因为FlowRule需要存储到device对应的master控制器节点的FlowRuleStore中，并由master节点下发到对应的device，具体的操作过程看DistributedFlowRuleStore的源码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Overridepublic void storeBatch(FlowRuleBatchOperation operation) &#123; if (operation.getOperations().isEmpty()) &#123; notifyDelegate(FlowRuleBatchEvent.completed( new FlowRuleBatchRequest(operation.id(), Collections.emptySet()), new CompletedBatchOperation(true, Collections.emptySet(), operation.deviceId()))); return; &#125; DeviceId deviceId = operation.deviceId(); NodeId master = mastershipService.getMasterFor(deviceId); if (master == null) &#123; log.warn("No master for &#123;&#125; : flows will be marked for removal", deviceId); updateStoreInternal(operation); notifyDelegate(FlowRuleBatchEvent.completed( new FlowRuleBatchRequest(operation.id(), Collections.emptySet()), new CompletedBatchOperation(true, Collections.emptySet(), operation.deviceId()))); return; &#125; if (Objects.equals(local, master)) &#123; storeBatchInternal(operation); return; &#125; log.trace("Forwarding storeBatch to &#123;&#125;, which is the primary (master) for device &#123;&#125;", master, deviceId); clusterCommunicator.unicast(operation, APPLY_BATCH_FLOWS, serializer::encode, master) .whenComplete((result, error) -&gt; &#123; if (error != null) &#123; log.warn("Failed to storeBatch: &#123;&#125; to &#123;&#125;", operation, master, error); Set&lt;FlowRule&gt; allFailures = operation.getOperations() .stream() .map(op -&gt; op.target()) .collect(Collectors.toSet()); notifyDelegate(FlowRuleBatchEvent.completed( new FlowRuleBatchRequest(operation.id(), Collections.emptySet()), new CompletedBatchOperation(false, allFailures, deviceId))); &#125; &#125;);&#125; 需要注意的是，若当前控制器不是对应device的master节点，storeBatch会使用ClusterCommunicationService服务的unicast方法，将该FlowRuleBatchOperation发送到对应的master控制器节点，Remote节点处理完成后会将处理的结果告诉该控制器节点。同时，DistributedFlowRuleStore使用ClusterCommunicationService服务的addSubscriber来监听东西向发送的FlowRule消息，并做出对应的处理。下面的APPLY_BATCH_FLOWS消息表示Remote节点将Flow Rules交给本地节点协助下发，而REMOTE_APPLY_COMPLETED消息则表示由Remote节点协助本地节点下发的Flow Rule已经下发完成，并调用notifyDelegate产生事件。 1234567891011121314private void registerMessageHandlers(ExecutorService executor) &#123; clusterCommunicator.addSubscriber(APPLY_BATCH_FLOWS, new OnStoreBatch(), executor); clusterCommunicator.&lt;FlowRuleBatchEvent&gt;addSubscriber( REMOTE_APPLY_COMPLETED, serializer::decode, this::notifyDelegate, executor); clusterCommunicator.addSubscriber( GET_FLOW_ENTRY, serializer::decode, flowTable::getFlowEntry, serializer::encode, executor); clusterCommunicator.addSubscriber( GET_DEVICE_FLOW_ENTRIES, serializer::decode, flowTable::getFlowEntries, serializer::encode, executor); clusterCommunicator.addSubscriber( REMOVE_FLOW_ENTRY, serializer::decode, this::removeFlowRuleInternal, serializer::encode, executor); clusterCommunicator.addSubscriber( FLOW_TABLE_BACKUP, serializer::decode, flowTable::onBackupReceipt, serializer::encode, executor);&#125; 最后，storeBatch中调用notifyDelegate函数向FlowRuleStoreDelegate通告FlowRuleStore中产生的事件，事件的类型在FlowRuleBatchEvent中定义。前一篇文章已经分析过，AbstractStore实现了notifyDelegate方法，而DistributedFlowRuleStore继承了AbstractStore类，因此可以调用notifyDelegate方法。 123456789101112131415......notifyDelegate(FlowRuleBatchEvent.requested(new FlowRuleBatchRequest(operation.id(), currentOps), operation.deviceId()));....../*** Notifies the delegate with the specified event.** @param event event to delegate*/protected void notifyDelegate(E event) &#123; if (delegate != null) &#123; delegate.notify(event); &#125;&#125; 上述代码块中delegate成员是在FlowRuleManager中注册到FlowRuleStore中来的，实现代码如下： 1234567891011private final FlowRuleStoreDelegate delegate = new InternalStoreDelegate();······@Activatepublic void activate(ComponentContext context) &#123; ...... store.setDelegate(delegate); eventDispatcher.addSink(FlowRuleEvent.class, listenerRegistry); deviceService.addListener(deviceListener); ...... log.info("Started");&#125; FlowRuleManager的内部类实现FlowRuleStoreDelegate接口，通过实现notify函数来处理来自FlowRueStore中产生的事件。这里post函数时最终会使用EventDeliveryService调度事件，其它应用组件通过实现FlowRuleListener接口，创建监听者并注册到FlowRuleManager中即可监听post抛出的事件，通过FlowRuleService.addListener()完成监听者的注册。ONOS中的StatisticManager模块中有一个实现了FlowRuleListener接口的内部类。根据上面的分析过程，storeBatch函数会产生BATCH_OPERATION_COMPLETED类型的事件，因此会通过FlowRuleProvider FlowRuleProvider = getProvider(deviceId)获取ProviderId，getProvider函数在AbstractProviderRegistry类中实现，FlowRuleManager继承了这个类，所有的Provider都会注册到FlowRuleManager，并保存在一个map中，具体实现查看AbstractProviderRegistry的源码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344// Store delegate to re-post events emitted from the store.private class InternalStoreDelegate implements FlowRuleStoreDelegate &#123; // TODO: Right now we only dispatch events at individual FlowEntry level. // It may be more efficient for also dispatch events as a batch. @Override public void notify(FlowRuleBatchEvent event) &#123; final FlowRuleBatchRequest request = event.subject(); switch (event.type()) &#123; case BATCH_OPERATION_REQUESTED: // Request has been forwarded to MASTER Node, and was request.ops().forEach( op -&gt; &#123; switch (op.operator()) &#123; case ADD: post(new FlowRuleEvent(RULE_ADD_REQUESTED, op.target())); break; case REMOVE: post(new FlowRuleEvent(RULE_REMOVE_REQUESTED, op.target())); break; case MODIFY: //TODO: do something here when the time comes. break; default: log.warn("Unknown Flow operation operator: &#123;&#125;", op.operator()); &#125; &#125; ); DeviceId deviceId = event.deviceId(); FlowRuleBatchOperation batchOperation = request.asBatchOperation(deviceId); FlowRuleProvider FlowRuleProvider = getProvider(deviceId); if (FlowRuleProvider != null) &#123; FlowRuleProvider.executeBatch(batchOperation); &#125; break; case BATCH_OPERATION_COMPLETED: ...... default: break; &#125; &#125;&#125; 以OpenFlow为例，OpenFlowRuleProvider实现了FlowRuleProvider接口，并使用FlowRuleProviderRegistry服务将该Provider注册到FlowRuleManager上。OpenFlowRuleProvider中的executeBatch的方法会将FlowRuleBatchOperation转化成OpenFlow的消息格式并下发到对应的交换机上。 1234567891011@Reference(cardinality = ReferenceCardinality.MANDATORY_UNARY)protected FlowRuleProviderRegistry providerRegistry;......private FlowRuleProviderService providerService;......@Activateprotected void activate(ComponentContext context) &#123; ...... providerService = providerRegistry.register(this); ......&#125; 以上就是FlowRule子系统下发flow rule的过程了，需要注意的是，任何ONOS instance可以向flow service请求对网络中的任何设备下发flow rule，但当这个网络设的master不是当前的ONOS instance时，该flow rule会被发送到设备的master instance，最终由master instance完成flow rule的下发操作。具体的实现过程在上面已经结合代码进行分析了，如下图所示： 3. Flow Rule的存储Flow rule的存储通过DistributedFlowRuleStore来实现，实现的接口服务是FlowRuleStore，需要考虑存储，备份，以及同步等问题。需要注意的是，ONOS会存储Flow rule并保持控制器和网络设备中Flow rule信息的一致性，若控制器发现了网络设备中有控制器没有存储的Flow rule条目，ONOS会将该Flow rule删除。同时，当master控制器对它的subnet中的device下发Flow rule信息后，会选择一个或多个（默认设置是2个备份节点，参考DistributedFlowRuleStore源码）其它的standby节点备份flowrule信息，从而使得当前节点down掉后能够恢复Flow rule信息。通常优先选择当前节点down掉后，接管该subnet的standby节点作为备份节点。 注： ONOS控制器各个node节点与device设备有三种mastership关系： NONE：这意味着node并不了解该设备，或仅仅是无法与其交互 STANDBY：此时node已经有对设备的认识，并可以读取其状态，但无法管理、控制该设备 MASTER：此时node认识设备并对其有完全的控制权 4. 总结总的来说，Flow Rule Subsystem的实现是比较复杂的，但其代码结构却很清晰。本文分析了Flow Rule子系统的代码结构，并结合Flow Rule的下发过程代码简单分析了Flow Rule子系统。若要了解Flow Rule的更多实现细节，需要进一步的阅读源码。 参考： ONOS System Components ONOS Flow Rule Subsystem]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ONOS子系统结构和事件分发处理机制]]></title>
      <url>%2F2017%2F01%2F05%2FONOS%E5%AD%90%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84%E5%92%8C%E4%BA%8B%E4%BB%B6%E5%88%86%E5%8F%91%E5%A4%84%E7%90%86%E6%9C%BA%E5%88%B6%2F</url>
      <content type="text"><![CDATA[ONOS是一个支持分布式的复杂网络操作系统，ONOS的设计高度层次化，模块化和抽象化，ONOS不同的模块和组件一般都使用特定的接口类型和异步事件机制通信协作。因此，理解ONOS子系统结构和事件分发处理机制对进一步深入了解ONOS是有很大帮助的。 1. ONOS子系统结构ONOS有很多子系统，但不同的子系统的层次和结构是相同的。下面是ONOS子系统的结构图： ONOS子系统主要包括App，Core，Provider，Protocol四部分。其中，Core是对网络的抽象，是协议无关的(protocol agnostic), 对上提供统一抽象的北向接口。Core中的组件主要包括Manager和Store，如FlowRuleManager和FlowRuleStore等。而Provider是协议相关的，主要为ONOS Core提供抽象的数据类型，Provider通过Core提供的ProviderService接口向Core注入网络信息，Provider也会暴露Provider接口给Core，接收来自Core的command消息。Protocol模块则是根据特定的协议类型通网路设备建立连接，Protocol模块一般是和对应的Provider模块共同启动的。 其中，Core中的Manager和Store是本次分析的重点。Manager对北实现Service和AdminService接口，对南实现ProviderRegistry和 ProviderService接口。Store则负责数据的存储，查询，更新以及东西向同步等，所有来自Manager中与数据相关的操作都会通过Store来完成。另外，Manager也会将Store中的事件抛出并实现ListenerService接口，其它应用通过ListenerService接口即可实现事件的监听，下面将详细分析这一过程。 2. ONOS系统事件分发处理机制2.1 了解ONOS系统中的事件Event和EventSink事件一般是由Store产生，用一种特定的类来表示一种事件类型，如AppIdEvent，DeviceEvent，FLowRuleEvent等，所有的事件类型实现Event接口，Event包括事件类型和事件主题，分别通过枚举类型和字符串类型来表示，表示一种特定的事件类型。每个事件最终会分发到一个对应的事件槽（EventSink），即事件传播处理的终点，系统调用事件槽的process函数处理对应的事件。下面分别是Event和EventSink的接口定义源码，二者都是泛型接口，接口的源码注释清楚的说明了这两个接口的作用。 Event接口：12345678910111213141516171819202122232425262728/** * Abstraction of an of a time-stamped event pertaining to an arbitrary subject. */public interface Event&lt;T extends Enum, S&gt; &#123; /** * Returns the timestamp of when the event occurred, given in milliseconds * since the start of epoch. * * @return timestamp in milliseconds */ long time(); /** * Returns the type of the event. * * @return event type */ T type(); /** * Returns the subject of the event. * * @return subject to which this event pertains */ S subject();&#125; EventSink接口： 12345678910111213141516171819/** * Abstraction of an event sink capable of processing the specified event types. */public interface EventSink&lt;E extends Event&gt; &#123; /** * Processes the specified event. * * @param event event to be processed */ void process(E event); /** * Handles notification that event processing time limit has been exceeded. */ default void onProcessLimit() &#123; &#125;&#125; 2.2 事件的分发服务EventDeliveryService 上面是EventDeliveryService的UML图，可以很容易的发现EventDeliveryService继承了两个接口，EventDispatcher和EventSinkRegistry，前者负责事件的分发（post），后者负责事件槽的管理（addSink和removeSink），ONOS子系统通过使用该服务，就能实现将事件正确分发到对应的事件槽，EventDeliveryService一般在子系统的Manager中使用。 2.3 EventDeliveryService服务的实现EventDeliveryService服务是通过CoreEventDispatcher类来实现，该类被声明为一个OSGi Component，由OSGi进行管理。废话不多说，还是直接看CoreEventDispatcher的UML结构图： 由于该类比较复杂，没有显示该类的成员变量。事件的最终分发处理是由内部类DispatchLoop处理，该类实现了Runnable接口，从而使用独立的线程处理特定的事件组。DispatchLoop里有一个保存事件队列的重要成员变量eventsQueue，声明如下： 12345678910111213// Auxiliary event dispatching loop that feeds off the events queue.private class DispatchLoop implements Runnable &#123; private final String name; private volatile boolean stopped; private volatile EventSink lastSink; // Means to detect long-running sinks private final Stopwatch stopwatch = Stopwatch.createUnstarted(); private TimerTask watchdog; private volatile Future&lt;?&gt; dispatchFuture; private final BlockingQueue&lt;Event&gt; eventsQueue; private final ExecutorService executor; ......&#125; eventsQueue是BlockingQueue类型，是一个阻塞队列，关于Java阻塞队列的功能和作用，参考：聊聊并发（七）——Java中的阻塞队列。EventDeliveryService的post方法最终会调用DispatchLoop的add方法将事件加入到这个队列，是程序主动调用的，DispatchLoop里的线程方法（run）会不断的取出事件并调用对应的事件槽处理函数处理对应事件。熟悉多线程协作以及设计模式的朋友应该会注意到这里所用的也就是生产者-消费者模式，参考：聊聊并发——生产者消费者模式。 1234567891011121314151617181920212223242526272829303132333435@Overridepublic void run() &#123; stopped = false; log.info("Dispatch loop initiated"); while (!stopped) &#123; try &#123; // Fetch the next event and if it is the kill-pill, bail Event event = eventsQueue.take(); if (event == KILL_PILL) &#123; break; &#125; process(event); &#125; catch (InterruptedException e) &#123; log.warn("Dispatch loop interrupted"); &#125; catch (Exception | Error e) &#123; log.warn("Error encountered while dispatching event:", e); &#125; &#125; log.info("Dispatch loop terminated");&#125;// Locate the sink for the event class and use it to process the event@SuppressWarnings("unchecked")private void process(Event event) &#123; EventSink sink = getSink(event.getClass()); if (sink != null) &#123; lastSink = sink; stopwatch.start(); sink.process(event); stopwatch.reset(); &#125; else &#123; log.warn("No sink registered for event class &#123;&#125;", event.getClass().getName()); &#125;&#125; 上面就是CoreEventDispatcher分发处理事件到对应事件槽的大概流程，这里就不对CoreEventDispatcher的实现细节进一步分析了，要了解程序的更多实现细节，需要阅读源码。 2.4 添加事件监听者处理事件下面是ONOS子系统中的事件分发示意图： Manager对数据的操作导致Store产生事件，Store通过StoreDelegate的notify方法向Manager通告事件。AbstractStore类中有基本Store接口的实现，一般Store的实现类都会继承AbstractStore基础类，该类中的notifyDelegate方法会调用StoreDelegate的notify方法。Manager使用内部类实现StoreDelegate接口，notify方法的实现会调用post方法，post方法最终使用EventDeliveryService服务分发事件。post方法在AbstractListenerManager或AbstractListenerProviderRegistry中有实现，Manager组件一般都会继承AbstractListenerManager或AbstractListenerProviderRegistry基础类。下面是AbstractStore和AbstractListenerProviderRegistry的UML图如下所示： 外部应用通过实现EventListener接口构造一个事件监听者，使用ListenerService的addListener方法完成监听者的注册，AbstractListenerManager和AbstractListenerProviderRegistry类都实现了ListenerService接口。AbstractListenerManager或AbstractListenerProviderRegistry基础类中有一个重要的对象成员： 123......protected final ListenerRegistry&lt;E, L&gt; listenerRegistry = new ListenerRegistry&lt;&gt;();..... 监听者注册最终会使用调用该成员对象的addListener方法，ListenerRegistry实现了ListenerService和EventSink接口，从而将事件(Event)，事件槽(EventSink)，监听者(EventListener)联系起来。 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * Base implementation of an event sink and a registry capable of tracking * listeners and dispatching events to them as part of event sink processing. */public class ListenerRegistry&lt;E extends Event, L extends EventListener&lt;E&gt;&gt; implements ListenerService&lt;E, L&gt;, EventSink&lt;E&gt; &#123; ...... /** * Set of listeners that have registered. */ protected final Set&lt;L&gt; listeners = new CopyOnWriteArraySet&lt;&gt;(); @Override public void addListener(L listener) &#123; checkNotNull(listener, "Listener cannot be null"); listeners.add(listener); &#125; @Override public void removeListener(L listener) &#123; checkNotNull(listener, "Listener cannot be null"); if (!listeners.remove(listener)) &#123; log.warn("Listener &#123;&#125; not registered", listener); &#125; &#125; @Override public void process(E event) &#123; for (L listener : listeners) &#123; try &#123; lastListener = listener; lastStart = System.currentTimeMillis(); if (listener.isRelevant(event)) &#123; listener.event(event); &#125; lastStart = 0; &#125; catch (Exception error) &#123; reportProblem(event, error); &#125; &#125; &#125; ......&#125; ListenerRegistry使用线程安全的集合CopyOnWriteArraySet管理监听者，EventSink的process方法就是逐个的执行EventListener的event方法。Manager使用EventDeliveryService的addSink方法将自己管理的事件和对应的事件槽联系起来。下面是FlowRuleManager的代码示例： 12345678910private final FlowRuleStoreDelegate delegate = new InternalStoreDelegate();······@Activatepublic void activate(ComponentContext context) &#123; ...... store.setDelegate(delegate); eventDispatcher.addSink(FlowRuleEvent.class, listenerRegistry); ...... log.info("Started");&#125; 3. 总结总的来说，ONOS子系统功能复杂但结构清晰，ONOS子系统的结构具有模块化，层次化，抽象化的特点。Manager是子系统的核心，负责将服务，存储，以及事件联系起来。Manager实现ListenerService接口，管理事件监听者的注册和移除，事件的分发和处理调度由EventDeliveryService统一管理。 参考： ONOS System Components 聊聊并发（七）——Java中的阻塞队列 聊聊并发——生产者消费者模式]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ONOS中的OpenFlow Channel状态机解析]]></title>
      <url>%2F2016%2F12%2F10%2FONOS%E4%B8%AD%E7%9A%84OpenFlow-Channel%E7%8A%B6%E6%80%81%E6%9C%BA%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[ONOS使用OFChannelHandler类来处理交换机和控制器的信道连接，同时将switch message分发到合适的位置，代码在package org.onosproject.openflow.controller.impl中。 1. OpenFlow状态机：ChanelState在OFChannelHandler类中，最重要的就是一个ChanelState的枚举类了，枚举类中的各个枚举实例表示Channel所处的状态，用来描述OpenFlow状态机信息，在枚举类中添加了处理OpenFlow消息的方法，各个枚举实例也根据自身的状态重写了部分方法。 OpenFlow状态机共定义了8种状态(INIT, WAIT_HELLO, WAIT_FEATURES_REPLY, WAIT_PORT_DESC_REPLY, WAIT_CONFIG_REPLY, WAIT_DESCRIPTION_STAT_REPLY, WAIT_SWITCH_DRIVER_SUB_HANDSHAKE, ACTIVE)，任何时候，Channel处于状态机中的任意一种状态。每个状态（枚举实例）都有一个默认初始化参数，其中false表示交换机握手没有成功，true表示交换机握手成功，枚举类的构造函数和获取交换机握手状态的代码块如下： 123456789101112private final boolean handshakeComplete;ChannelState(boolean handshakeComplete) &#123; this.handshakeComplete = handshakeComplete;&#125;/** * Is this a state in which the handshake has completed? * @return true if the handshake is complete */public boolean isHandshakeComplete() &#123; return handshakeComplete;&#125; 2. OpenFlow状态机启动流程ONOS使用netty通信框架（参考：Netty 实战），在这里就不考虑netty相关的NIO过程了。ONOS启动ChannelHander对应的实例时，构造函数OFChannelHandler(Controller controller) 会引用当前的控制器实例，同时会将stage初始化为ChannelState.INIT状态，表示Channel处于连接之前（代码注释很清楚）。注意，OFChannelHandler中的state变量是volatile类型，这是为了确保HandshakeTimeoutHandler检测到的state状态都是最新的，至于volatile关键字的用法，建议参考：Java并发编程：volatile关键字解析 当Channel检测到交换机连接时，会调用OFChannelHandler类中的channelConnected函数： 1234567891011121314@Overridepublic void channelConnected(ChannelHandlerContext ctx, ChannelStateEvent e) throws Exception &#123; channel = e.getChannel(); log.info("New switch connection from &#123;&#125;", channel.getRemoteAddress()); /* hack to wait for the switch to tell us what it's max version is. This is not spec compliant and should be removed as soon as switches behave better. */ //sendHandshakeHelloMessage(); setState(ChannelState.WAIT_HELLO);&#125; 在这里，state被设置为ChannelState.WAIT_HELLO状态，顾名思义，就是等待交换机的hello消息了。当Channel得到交换机发往控制器的消息时，就会调用messageReceived函数，messageReceived又会调用当前状态机实例的processOFMessage方法，处理OFMessage消息，各种不同的OFMessage消息对应了不同的消息处理函数，在ChannelState枚举类中都有定义。需要注意的是，不同的状态机实例可能根据当前状态重写ChannelState中的消息处理函数，因此同一消息类型在不同的状态下的处理逻辑可能是不一样的。OFMessage处理完成后，调用setState方法来切换状态机，握手成功后，状态机处于ACTIVE(true)状态。 12345678910111213141516@Overridepublic void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception &#123; if (e.getMessage() instanceof List) &#123; @SuppressWarnings("unchecked") List&lt;OFMessage&gt; msglist = (List&lt;OFMessage&gt;) e.getMessage(); for (OFMessage ofm : msglist) &#123; // Do the actual packet processing state.processOFMessage(this, ofm); &#125; &#125; else &#123; state.processOFMessage(this, (OFMessage) e.getMessage()); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889/** * Process an OF message received on the channel and * update state accordingly. * * The main "event" of the state machine. Process the received message, * send follow up message if required and update state if required. * * Switches on the message type and calls more specific event handlers * for each individual OF message type. If we receive a message that * is supposed to be sent from a controller to a switch we throw * a SwitchStateExeption. * * The more specific handlers can also throw SwitchStateExceptions * * @param h The OFChannelHandler that received the message * @param m The message we received. * @throws SwitchStateException if the switch is not bound to the channel * @throws IOException if unable to send message back to the switch */void processOFMessage(OFChannelHandler h, OFMessage m) throws IOException, SwitchStateException &#123; switch(m.getType()) &#123; case HELLO: processOFHello(h, (OFHello) m); break; case BARRIER_REPLY: processOFBarrierReply(h, (OFBarrierReply) m); break; case ECHO_REPLY: processOFEchoReply(h, (OFEchoReply) m); break; case ECHO_REQUEST: processOFEchoRequest(h, (OFEchoRequest) m); break; case ERROR: processOFError(h, (OFErrorMsg) m); break; case FEATURES_REPLY: processOFFeaturesReply(h, (OFFeaturesReply) m); break; case FLOW_REMOVED: processOFFlowRemoved(h, (OFFlowRemoved) m); break; case GET_CONFIG_REPLY: processOFGetConfigReply(h, (OFGetConfigReply) m); break; case PACKET_IN: processOFPacketIn(h, (OFPacketIn) m); break; case PORT_STATUS: processOFPortStatus(h, (OFPortStatus) m); break; case QUEUE_GET_CONFIG_REPLY: processOFQueueGetConfigReply(h, (OFQueueGetConfigReply) m); break; case STATS_REPLY: // multipart_reply in 1.3 processOFStatisticsReply(h, (OFStatsReply) m); break; case EXPERIMENTER: processOFExperimenter(h, (OFExperimenter) m); break; case ROLE_REPLY: processOFRoleReply(h, (OFRoleReply) m); break; case GET_ASYNC_REPLY: processOFGetAsyncReply(h, (OFAsyncGetReply) m); break; // The following messages are sent to switches. The controller // should never receive them case SET_CONFIG: case GET_CONFIG_REQUEST: case PACKET_OUT: case PORT_MOD: case QUEUE_GET_CONFIG_REQUEST: case BARRIER_REQUEST: case STATS_REQUEST: // multipart request in 1.3 case FEATURES_REQUEST: case FLOW_MOD: case GROUP_MOD: case TABLE_MOD: case GET_ASYNC_REQUEST: case SET_ASYNC: case METER_MOD: default: illegalMessageReceived(h, m); break; &#125;&#125; 以上就是状态机启动的基本流程了，更详细的过程看OFChannelHandler源码。 参考： ONOS中Channel状态机分析 ONOS中控制器与交换机建立连接的过程 OpenFlow state machine]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[OSGi简介与基于OSGi框架（Felix）的简单应用实现]]></title>
      <url>%2F2016%2F12%2F08%2FOSGi%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%9F%BA%E4%BA%8EOSGi%E6%A1%86%E6%9E%B6%EF%BC%88Felix%EF%BC%89%E7%9A%84%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
      <content type="text"><![CDATA[OSGi(Open Service Gateway Initiative)，其英文定义为：The Dynamic Module System for Java。由此可见，OSGi的主要职责就是为了让开发者能够构建动态化、模块化的Java系统。使用OSGi，系统的各个组件就像插件一样，暴露特定的接口，实现“即插即用”。 1. OSGi的基本概念1.1 bundle在OSGi中，各个组件以bundle的形式存在，但从形式上讲，bundle也就是在META-INF目录下的MANIFEST.MF文件中加入了OSGi特定描述的jar包。bundle的生命周期被OSGi框架所管理，具有如下几个状态：INSTALLED, RESOLVED,STARTING, ACTIVE, STOPPING, UNINSTALLED。bundle各个生命周期状态的转换如下图所示： bundle通过配置jar包中的MANIFEST.MF文件控制从bundle导出的包。而没有导出的包在bundle外部不能使用，这样就很好的完成了内部类和外部类的隔离。bundle可以被动态的安装、启动、停止和卸载。bundle是服务（Service）和组件（Component）的载体。事实上，不管是通过BundleContext注册和获取服务的方式，还是Declarative Service进行声明注入的方式，都是在编写bundle。 在OSGi中，每个bundle都有独立于其它bundle的ClassLoader，正因为这样，各个bundle的类是相互隔离的。但一个bundle可能会用到另外一个bundle的类，bundle之间的交户通过以下三种方式实现： Export-Package：根据OSGi规范，每个工程可以通过声明Export-Package对外提供访问此工程中的类和接口，可以先把bundle导出，再导入到需要调用的bundle中，默认情况下一个bundle中所有的Package对外都是不可见的。 OSGi服务：通过将要对外提供功能声明为OSGi的服务实现面向接口、面向服务式的设计。一个bundle作为Service的提供方，对外提供Service，使用者可以查找到提供的Service。提供使用Service有三种方式： 通过BundleContext（bundle的上下文）来提供和获取； 使用Declarative Service来获取； 使用Blueprint来获取； Event：OSGi的Event服务也是实现模块交互的一种可选方法，模块对外发布事件，订阅了此事件的模块就会相应地接收到消息，从而做出反应，以达到交互的目的。 1.2 OSGi Service 一个OSGi Service就是注册到OSGi框架中的Java对象的引用。在注册的时候可以设置这个Service的属性，从而在获取Service的时候可以进行过滤。OSGi拥有一个集中的服务注册中心，它遵循发布-查询-绑定模型，如下图所示。 bundle可以通过bundle的上下文去注册Service或去查询Service，获取对应服务的对象引用。当然还有其它方式实现OSGi Service，就是上面提到的声明式服务和Blueprint服务。关于OSGi Service使用方式的选择问题，参考： OSGi中该使用Blueprint还是声明式服务? 后面的例子将介绍使用BundleContext注册和获取OSGi Service。 1.3 OSGi框架OSGi框架可以看做实现了OSGi规范的容器，使用OSGi框架，可以实现各种bundle的“即插即用”，目前流行的框架包括Equinox和Felix，下面的简单应用是基于Felix框架实现的。 2. 基于OSGi框架（Felix）简单应用的实现下面将介绍使用Maven工具和Felix框架实现OSGi简单应用，源码链接： osgi-provider osgi-consumer 2.1 使用BundleContext注册和获取OSGi Service使用两个bundle分别实现服务的注册和获取，由服务提供者（Service Provider）注册OSGi服务，服务消费者（Service Consumer）获取服务，Service Provider使用接口提供服务，而Service Consumer也将使用接口获取对应服务的实例化对象。 2.1.1 定义服务并注册 定义服务接口HelloWorldService 12345package org.hhb.osgi.provider.api;public interface HelloWorldService &#123; public void hello();&#125; 实现服务HelloWorldServiceImpl 12345678910package org.hhb.osgi.provider.impl;import org.hhb.osgi.provider.api.HelloWorldService;public class HelloWorldServiceImpl implements HelloWorldService &#123; @Override public void hello()&#123; System.out.println(&quot;Hello World !&quot;); &#125;&#125; 实现BundleActivator接口注册服务并实例化服务对象 123456789101112131415161718192021222324package org.hhb.osgi.provider;import org.hhb.osgi.provider.api.HelloWorldService;import org.hhb.osgi.provider.impl.HelloWorldServiceImpl;import org.osgi.framework.BundleActivator;import org.osgi.framework.BundleContext;import org.osgi.framework.ServiceRegistration;public class HelloActivator implements BundleActivator &#123; private ServiceRegistration registration; @Override public void start(BundleContext bundleContext) throws Exception &#123; registration = bundleContext.registerService( HelloWorldService.class.getName(), new HelloWorldServiceImpl(), null); &#125; @Override public void stop(BundleContext bundleContext) throws Exception &#123; registration.unregister(); &#125;&#125; 需要注意的是，上面的start和stop方法将分别在bundle start和stop时被调用。 使用maven-bundle-plugin插件打包bundle 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.hhb&lt;/groupId&gt; &lt;artifactId&gt;osgi-provider&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;bundle&lt;/packaging&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.felix&lt;/groupId&gt; &lt;artifactId&gt;maven-bundle-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt; &lt;extensions&gt;true&lt;/extensions&gt; &lt;configuration&gt; &lt;instructions&gt; &lt;Bundle-SymbolicName&gt;$&#123;pom.groupId&#125;.$&#123;pom.artifactId&#125;&lt;/Bundle-SymbolicName&gt; &lt;Bundle-Vendor&gt;Apache Felix&lt;/Bundle-Vendor&gt; &lt;Bundle-Activator&gt;org.hhb.osgi.provider.HelloActivator&lt;/Bundle-Activator&gt; &lt;/instructions&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.felix&lt;/groupId&gt; &lt;artifactId&gt;org.osgi.core&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 这样编译打包后，就会在jar包下的META-INF文件夹下生成一个描述bundle信息的MANIFEST.MF文件。 2.1.2 获取并使用服务 定义服务消费类HelloWorldConsumer 12345678910111213141516171819202122232425262728293031323334package org.hhb.osgi.consumer;import javax.swing.Timer;import java.awt.event.ActionEvent;import java.awt.event.ActionListener;import org.hhb.osgi.provider.api.HelloWorldService;public class HelloWorldConsumer implements ActionListener &#123; private final HelloWorldService service; private final Timer timer; public HelloWorldConsumer(HelloWorldService service) &#123; super(); this.service = service; timer = new Timer(1000, this); &#125; public void startTimer()&#123; timer.start(); &#125; public void stopTimer() &#123; timer.stop(); &#125; @Override public void actionPerformed(ActionEvent e) &#123; service.hello(); &#125;&#125; 使用BundleContext获取服务并使用 123456789101112131415161718192021222324package org.hhb.osgi.consumer;import org.osgi.framework.BundleActivator;import org.osgi.framework.BundleContext;import org.osgi.framework.ServiceReference;import org.hhb.osgi.provider.api.HelloWorldService;public class HelloWorldActivator implements BundleActivator &#123; private HelloWorldConsumer consumer; @Override public void start(BundleContext bundleContext) throws Exception &#123; ServiceReference reference = bundleContext.getServiceReference(HelloWorldService.class.getName()); consumer = new HelloWorldConsumer((HelloWorldService) bundleContext.getService(reference)); consumer.startTimer(); &#125; @Override public void stop(BundleContext bundleContext) throws Exception &#123; consumer.stopTimer(); &#125;&#125; pom文件配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.hhb&lt;/groupId&gt; &lt;artifactId&gt;osgi-consumer&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;bundle&lt;/packaging&gt; &lt;name&gt;osgi-consumer&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.felix&lt;/groupId&gt; &lt;artifactId&gt;org.osgi.core&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hhb&lt;/groupId&gt; &lt;artifactId&gt;osgi-provider&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.felix&lt;/groupId&gt; &lt;artifactId&gt;maven-bundle-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt; &lt;extensions&gt;true&lt;/extensions&gt; &lt;configuration&gt; &lt;instructions&gt; &lt;Bundle-SymbolicName&gt;$&#123;pom.groupId&#125;.$&#123;pom.artifactId&#125;&lt;/Bundle-SymbolicName&gt; &lt;Bundle-Vendor&gt;Apache Felix&lt;/Bundle-Vendor&gt; &lt;Bundle-Activator&gt;org.hhb.osgi.consumer.HelloWorldActivator&lt;/Bundle-Activator&gt; &lt;/instructions&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2.1.3 在Felix中运行服务 下载Felix Framework Distribution 运行Felix 12345$java -jar bin/felex.jar____________________________Welcome to Apache Felix Gogog! 运行bundle 12345678910111213g! g! install file:../osgi/osgi-provider-1.0-SNAPSHOT.jar 11:01:54 bundle ID: 8g! start 8 11:02:02 g! install file:../osgi/osgi-consumer-1.0-SNAPSHOT.jar 11:02:08 bundle ID: 9g! start 9 11:02:16 g! Hello World ! 11:02:19 Hello World !Hello World !Hello World !Hello World !stop 9 其中file:../osgi/osgi-consumer-1.0-SNAPSHOT.jar表示bundle文件的路径。 2.2 使用Export-Package提供Package给其它bundle使用很多情况下在bundle使用第三方库，如Guava，Netty时，并不希望以服务的方式获取，而希望使用Import Package就可以获取对应的包。而默认情况下，不同bundle中的包是相互隔离的，这时就需要使用Export-Package导出bundle中的包给其它bundle使用。 2.2.1 产生bundle并Export Package 定义接口HelloWorldService（同上） 接口实现类HelloWorldServiceImpl（同上） 配置pom 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.hhb&lt;/groupId&gt; &lt;artifactId&gt;osgi-provider&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;bundle&lt;/packaging&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.felix&lt;/groupId&gt; &lt;artifactId&gt;maven-bundle-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt; &lt;extensions&gt;true&lt;/extensions&gt; &lt;configuration&gt; &lt;instructions&gt; &lt;Bundle-SymbolicName&gt;$&#123;pom.groupId&#125;.$&#123;pom.artifactId&#125;&lt;/Bundle-SymbolicName&gt; &lt;Bundle-Vendor&gt;Apache Felix&lt;/Bundle-Vendor&gt; &lt;Export-Package&gt;org.hhb.osgi.provider.api, org.hhb.osgi.provider.impl&lt;/Export-Package&gt; &lt;/instructions&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.felix&lt;/groupId&gt; &lt;artifactId&gt;org.osgi.core&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 需要注意的是，激活器（bundle-Activator）对一个bundle来说不是必需的，也就是说，bundle的start过程并处于Active状态并不需要bundle-Activator。只有当构建一个bundle，并需要与OSGi API进行交换时，或者需要执行自定义的初始化/销毁动作，激活器才是必须的。事实上，前面使用bundle-Activator主要是为了注册服务并实例化服务对象，这样其它bundle就可以直接使用该服务了。 2.2.2 在另一bundle种使用外部包 定义服务消费类HelloWorldConsumer（同上） Import Package并使用 123456789101112131415161718192021222324252627282930package org.hhb.osgi.consumer;import com.google.common.collect.Lists;import org.osgi.framework.BundleActivator;import org.osgi.framework.BundleContext;import org.hhb.osgi.provider.impl.HelloWorldServiceImpl;import java.util.List;public class HelloWorldActivator implements BundleActivator &#123; private HelloWorldConsumer consumer; @Override public void start(BundleContext bundleContext) throws Exception &#123; //test for using third-party dependency package List&lt;String&gt; strings = Lists.newArrayList(&quot;I&quot;, &quot;use&quot;, &quot;guava&quot;, &quot;here&quot;); System.out.println(strings); //test for using my customized dependency package //ServiceReference reference = bundleContext.getServiceReference(HelloWorldService.class.getName()); consumer = new HelloWorldConsumer(new HelloWorldServiceImpl()); consumer.startTimer(); &#125; @Override public void stop(BundleContext bundleContext) throws Exception &#123; consumer.stopTimer(); &#125;&#125; pom的配置（同上） 需要注意的是，maven-bundle-plugin会根据类中声明的import的包信息导入所有的Package并写入MANIFEST-MF文件的Import-Package字段中，若自己在pom中定义Import-Package信息，需要注意不要遗漏相关的Package。 12345678910111213141516&lt;plugin&gt; &lt;groupId&gt;org.apache.felix&lt;/groupId&gt; &lt;artifactId&gt;maven-bundle-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.0&lt;/version&gt; &lt;extensions&gt;true&lt;/extensions&gt; &lt;configuration&gt; &lt;instructions&gt; &lt;Bundle-SymbolicName&gt;$&#123;pom.groupId&#125;.$&#123;pom.artifactId&#125;&lt;/Bundle-SymbolicName&gt; &lt;Bundle-Vendor&gt;Apache Felix&lt;/Bundle-Vendor&gt; &lt;Bundle-Activator&gt;org.hhb.osgi.consumer.HelloWorldActivator&lt;/Bundle-Activator&gt; &lt;!--&lt;Import-Package&gt;com.google.common.collect,javax.swing,org.osgi.framework, org.hhb.osgi.provider.api,org.hhb.osgi.provider.impl&lt;/Import-Package&gt;--&gt; &lt;/instructions&gt; &lt;/configuration&gt;&lt;/plugin&gt; 2.2.3 在Felix中运行服务 同上 2.2.4 bundle中使用外部包总结在Java程序中，用到外部包中的类几乎是必然的事情，在OSGI和MAVEN环境下，引用外部包的方法总结如下： java.开头的包，是JDK提供了，代码中直接import。 org.osgi开头的（包括core、compendium等），是osgi规范提供的，已经包含在osgi框架（Felix）中，开发时需要导入，但是发布程序中不需要包含，由Felix提供，实现方法是添加scope为provided的maven依赖，如： 123456&lt;dependency&gt; &lt;groupId&gt;org.apache.felix&lt;/groupId&gt; &lt;artifactId&gt;org.osgi.core&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 第三方jar包，可能有多个bundle共享的，直接osgi化，然后作为独立bundle安装到Felix中,如Guava，部署时只要将这些包作为一个独立的bundle并启动，其他bundle就可以通过直接Import-Package的方式来引用这些包。之所以能够这么做是因为这个jar已经osgi化了，查看jar包中的META-INF/MENIFEST.MF文件，可以看到这些jar包Export的包信息。 第三方的jar包，不考虑多个bundle共享，只确保一个bundle的独立依赖，可以把这些依赖的jar嵌入到开发的bundle中发布。maven中加入这些jar包的dependency的依赖项就可以在开发时引用了，但是发布到Felix框架时，我们要把这些jar包一起提供才行，方法是把这些jar包嵌入到我们的bundle中，使用maven-bundle-plugin，增加instructions配置*;scope=compile|runtime，这样maven在打包是就可以自动把这些依赖的jar包嵌入。要注意这些依赖的scope和Embed-Dependency的表述方式的匹配，具体Embed-Dependency可能的写法请参见maven-bundle-plugin在线文档。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入理解Java：抽象类和接口]]></title>
      <url>%2F2016%2F12%2F06%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%EF%BC%9A%E6%8A%BD%E8%B1%A1%E7%B1%BB%E5%92%8C%E6%8E%A5%E5%8F%A3%2F</url>
      <content type="text"><![CDATA[抽象类和接口是Java中的重要类型，对Java实现灵活的继承和多态有极其重要的作用。关于抽象类和接口的用法教程有很多，本篇文章主要用来记录Java中抽象类和接口的一些重要的概念和特殊的用法，从而加深对抽象类和接口的理解。 1. 关于抽象类抽象类可以不包含抽象方法，在这种情况下，这种类是用来定义子类的基类，这也是抽象类最常用的一种方式。抽象类的抽象方法不能在抽象类中实现，当子类继承一个抽象类时，该子类要么实现父类的所有抽象方法，要么将该子类定义为一个抽象类。虽然不能根据抽象类new一个对象实例，但抽象类也有构造方法，包括默认的和自定义的构造方法，当子类继承抽象类并生成一个对象时，会先调用抽象类的构造方法。 2. 关于接口2.1 接口的定义和声明由于接口中所有的数据域都是public、static、final，而且所有的方法都是public abstract，所以Java允许忽略这些修饰符。因此下面的接口是等价的： 1234interface A &#123; int k = 1; void m1();&#125; 等价于： 1234interface A &#123; public static final int k = 1; public abstract void m1();&#125; 接口中不能包含方法的实现，下面定义的接口类型是错误的： 12345interface A &#123; int k = 1; //接口中所有的方法都是public abstract，抽象方法不能在抽象类中实现 void m1() &#123;&#125;&#125; 但要注意的是继承该接口的子类实现接口的方法时要明确指明该方法的访问权限是public，不能是默认访问权限或其它访问权限，下面的是错误的： 1234567891011121314public class B implements A &#123; @Override void m1() &#123; System.out.println("m1" + k); &#125; @Override public String toString() &#123; return "class B"; &#125; public static void main(String[] args) &#123; B c = new B(); System.out.println(c); &#125;&#125; 正确的接口继承方式: 1234567891011121314public class B implements A &#123; @Override public void m1() &#123; System.out.println("m1" + k); &#125; @Override public String toString() &#123; return "class B"; &#125; public static void main(String[] args) &#123; B c = new B(); System.out.println(c); &#125;&#125; 2.2 使用接口声明对象的引用使用接口声明一个对象的引用时，实际上是将该对象向上转型为对应的接口类型，这样可以方便我们编写代码时与接口打交道，而不用考虑具体的实现。例如，可以使用List声明一个指向ArrayList对象的引用： 1List&lt;Apple&gt; apples = new ArrayList&lt;&gt;(); 在这里，ArrayList已经向上转型为List，这样声明可以方便我们想要修改实现的时候，只需在创建时修改它： 1List&lt;Apple&gt; apples = new LinkedList&lt;&gt;(); 因此，在创建一个具体对象时，应多考虑将其转型为一个对应的接口，然后在其余的代码中使用这个接口。这也呼应了Java编程中的“针对接口编程”的思想了。 注意： 由于一个类可以实现多个接口，接口也可以继承，因此可以通的接口类型声明一个对象的引用。而对象的属性是由类本身决定的，因此对该对象的本身来说，没有本质的差异。但由于引用可访问的方法是和声明的接口类型是相关的，因此不同的声明方式对使用者来说有区别的。如： 12private ConcurrentMap&lt;Integer,Group&gt; groupMap = new ConcurrentHashMap&lt;Integer, Group&gt;();private Map&lt;Integer,Group&gt; groupMap = new ConcurrentHashMap&lt;Integer, Group&gt;(); 这两种声明方式都可以引用一个线程安全的map，但若需要调用ConcurrentHashMap的putIfAbsent方法来保证map里面有且只有一个特定的资源，这种时候，就应该声明为ConcurrentHashMap，表明代码语义是跟一个支持同步语义的map进行交流，而不是一个普通的一般性的map。即使这样，两种声明方式在使用putIfAbsent时没有本质区别，这是因为最终调用的还是ConcurrentHashMap中实现的putIfAbsent方法，是线程安全的。 参考： 知乎：使用不同的接口声明对象引用 2.3 接口与匿名类接口不可以new，但可以用new产生一个实现接口的匿名类。如Swing中常用到的new ActionListener() { } ，就是在{}中重写ActionListen接口中的方法。 123456button2.addActionListener ( new ActionListener() &#123; publicvoid actionPerformed(ActionEvent e) &#123; System.out.println("你按了按钮"); &#125; &#125;); 2.4 函数式接口当一个接口只有一个抽象方法时，这个接口就是函数式接口，函数式接口用作lambda表达式的类型。详细内容请参考：Java 8 新特性：lambda表达式 2.5 Java 8接口中的默认方法Java 8中接口可以实现方法，而不需要实现类去实现方法，通过在接口方法中加入关键字default，就可以在接口中实现方法了。 为什么要有这个特性？首先，之前的接口是个双刃剑，好处是面向抽象而不是面向具体编程，缺陷是，当需要修改接口时候，需要修改全部实现该接口的类，目前的java 8之前的集合框架没有foreach方法，通常能想到的解决办法是在JDK里给相关的接口添加新的方法及实现。然而，对于已经发布的版本，是没法在给接口添加新方法的同时不影响已有的实现。所以引进的默认方法。他们的目的是为了解决接口的修改与现有的实现不兼容的问题。 引入接口的默认方法后，接口和抽象类有了更多的相同点了，但二者依然有区别，下面是Java 8抽象类和接口的对比： 相同点： 都是抽象类型； 都可以有实现方法（以前接口不行）； 都可以不需要实现类或者继承者去实现所有方法，（以前不行，现在接口中默认方法不需要实现者实现） 不同点： 抽象类不可以多重继承，接口可以（无论是多重类型继承还是多重行为继承）； 抽象类和接口所反映出的设计理念不同。其实抽象类表示的是”is-a”关系，接口表示的是”like-a”关系； 接口中定义的变量默认是public static final 型，且必须给其初值，所以实现类中不能改变其值；抽象类中的变量默认是 friendly 型，其值可以在子类中重新定义，也可以重新赋值。 注意： 若在实现类中实现了接口的默认方法，则最终会调用实现类的方法；若子接口覆盖了父接口的默认方法，则会调用子接口的默认方法；若子接口声明了和父接口一样的方法但没有实现，那么无论该方法是不是父接口的默认方法，在实现类中都要实现。看下面的例子： 1234567891011121314151617181920212223242526interface A &#123; void foo(); default void test() &#123; System.out.println("Calling A.test()"); &#125;&#125;interface B extends A &#123; default void foo() &#123; System.out.println("Calling B.foo()"); &#125; void test();&#125;public class C implements B &#123; //test() must be implemented in this class @Override public void test() &#123; System.out.println("Calling C.test()"); &#125; public static void main(String[] args)&#123; A obj = new C(); obj.foo();//Calling B.foo() obj.test();//Calling C.test() &#125;&#125; 关于接口的默认方法在Java 8的JDK库中有很多使用，可以参照Map，ConcurrentMap，ConcurrentHashMap学习接口的默认方法。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java 8新特性：流式处理]]></title>
      <url>%2F2016%2F12%2F04%2FJava-8%E6%96%B0%E7%89%B9%E6%80%A7%EF%BC%9A%E6%B5%81%E5%BC%8F%E5%A4%84%E7%90%86%2F</url>
      <content type="text"><![CDATA[声明：本篇博客很多内容引用自Java 8 中的 Streams API 详解和Java 8函数式编程，同时文中也有很多自己的理解和学习体会，希望通过这篇文章深入的介绍和总结Java 8的流式处理。 1. 什么是流Stream 不是集合元素，它不是数据结构并不保存数据，它是有关算法和计算的，它更像一个高级版本的 Iterator。原始版本的 Iterator，用户只能显式地一个一个遍历元素并对其执行某些操作；高级版本的 Stream，用户只要给出需要对其包含的元素执行什么操作，比如 “过滤掉长度大于 10 的字符串”、“获取每个字符串的首字母”等，Stream 会隐式地在内部进行遍历，做出相应的数据转换。 Stream 就如同一个迭代器（Iterator），单向，不可往复，数据只能遍历一次，遍历过一次后即用尽了，就好比流水从面前流过，一去不复返。 而和迭代器又不同的是，Stream 可以并行化操作，迭代器只能命令式地、串行化操作。顾名思义，当使用串行方式去遍历时，每个 item 读完后再读下一个 item。而使用并行去遍历时，数据会被分成多个段，其中每一个都在不同的线程中处理，然后将结果一起输出。Stream 的并行操作依赖于 Java7 中引入的 Fork/Join 框架（JSR166y）来拆分任务和加速处理过程。Java 的并行 API 演变历程基本如下： 1.0-1.4 中的 java.lang.Thread 5.0 中的 java.util.concurrent 6.0 中的 Phasers 等 7.0 中的 Fork/Join 框架 8.0 中的 Lambda Stream 的另外一大特点是，数据源本身可以是无限的。 总的来说，Stream是用函数编程的方式在集合类上进行复杂操作的工具。 2. 流的构成当我们使用一个流的时候，通常包括三个基本步骤： 获取一个数据源（source）→ 数据转换→执行操作获取想要的结果，每次转换原有 Stream 对象不改变，返回一个新的 Stream 对象（可以有多次转换），这就允许对其操作可以像链条一样排列，变成一个管道，如下图所示。 流的操作类型分为两种： Intermediate：一个流可以后面跟随零个或多个 intermediate 操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是惰性化的（lazy），就是说，仅仅调用到这类方法，并没有真正开始流的遍历。 Terminal：一个流只能有一个 terminal 操作，当这个操作执行后，流就被使用“光”了，无法再被操作。所以这必定是流的最后一个操作。Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果，或者一个 side effect。 在对于一个 Stream 进行多次转换操作 (Intermediate 操作)，每次都对 Stream 的每个元素进行转换，而且是执行多次，这样时间复杂度就是 N（转换次数）个 for 循环里把所有操作都做掉的总和吗？其实不是这样的，转换操作都是 lazy 的，多个转换操作只会在 Terminal 操作的时候融合起来，一次循环完成。我们可以这样简单的理解，Stream 里有个操作函数的集合，每次转换操作就是把转换函数放入这个集合中，在 Terminal 操作的时候循环 Stream 对应的集合，然后对每个元素执行所有的函数。 例如，下面的Stream没有Terminal操作，不会输出任何信息！ 123456List&lt;Integer&gt; nums = Arrays.asList(1,null,3,4,null,5);nums.stream() .filter(num -&gt; &#123; System.out.println(num); return num != null; &#125;); 使用Terminal操作后，所有的中间惰性操作才会执行： 1234567List&lt;Integer&gt; nums = Arrays.asList(1,null,3,4,null,5);nums.stream() .filter(num -&gt; &#123; System.out.println(num); return num != null; &#125;) .count(); 上面代码打印的信息如下： 1234561null34null5 还有一种操作被称为 short-circuiting。指的是： 对于一个 intermediate 操作，如果它接受的是一个无限大（infinite/unbounded）的 Stream，但返回一个有限的新 Stream。 对于一个 terminal 操作，如果它接受的是一个无限大的 Stream，但能在有限的时间计算出结果。 当操作一个无限大的 Stream，而又希望在有限时间内完成操作，则在管道内拥有一个 short-circuiting 操作是必要非充分条件。 3. 流的使用简单说，对 Stream 的使用就是实现一个 filter-map-reduce 过程，产生一个最终结果，或者导致一个副作用（side effect）。 3.1 流的构造与转换 流的构造过程就是对原来的集合进行包装，产生一个Stream对象，常见的构造流的方法如下： 123456789// 1. Individual valuesStream stream = Stream.of("a", "b", "c");// 2. ArraysString [] strArray = new String[] &#123;"a", "b", "c"&#125;;stream = Stream.of(strArray);stream = Arrays.stream(strArray);// 3. CollectionsList&lt;String&gt; list = Arrays.asList(strArray);stream = list.stream(); 流转换为其它数据结构 123456789// 1. ArrayString[] strArray1 = stream.toArray(String[]::new);// 2. CollectionList&lt;String&gt; list1 = stream.collect(Collectors.toList());List&lt;String&gt; list2 = stream.collect(Collectors.toCollection(ArrayList::new));Set set1 = stream.collect(Collectors.toSet());Stack stack1 = stream.collect(Collectors.toCollection(Stack::new));// 3. StringString str = stream.collect(Collectors.joining()).toString(); 一个 Stream 只可以使用一次，上面的代码为了简洁而重复使用了数次。 3.2 流的操作接下来，当把一个数据结构包装成 Stream 后，就要开始对里面的元素进行各类操作了。常见的操作可以归类如下。 Intermediate： map (mapToInt, flatMap 等)、 filter、 distinct、 sorted、 peek、 limit、 skip、 parallel、 sequential、 unordered Terminal： forEach、 forEachOrdered、 toArray、 reduce、 collect、 min、 max、 count、 anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 iterator Short-circuiting： anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 limi 需要注意的是所有的操作方法可接受的参数都是lambda表达式（没有参数的操作方法除外）。 3.2.1 collect(toList())该操作是由Stream生成一个列表，是一个及时操作。 3.2.2 mapmap将一个流转化为一个新的流，是惰性操作。操作过程如下图所示： 下面是一个转换大小写的例子： 123List&lt;String&gt; collected = Stream.of("a", "b", "hello") .map(string -&gt; string.toUpperCase()) //lambda .collect(Collectors.toList()); 注意：传给map的参数是一个lambda表达式，该lambda表达式必须是Function结构的实例，即lambda表达式只接受一个参数，并且返回一个值，接受参数类型和返回参数的类型可以不一样。Function接口如下图所示： 3.2.3 flatMapJava 8中，除了一些基本的对象类型，如String，Object等，流也可以是集合或数组类型，如：1234Stream&lt;String[]&gt;Stream&lt;Set&lt;String&gt;&gt;Stream&lt;List&lt;String&gt;&gt;Stream&lt;List&lt;Object&gt;&gt; 然而，流的很多操作，如filter，sum，distinct等以及收集器collectors的处理都不支持这些流类型。因此需要使用flatmap对这些类型的流做转换： 1234Stream&lt;String[]&gt; -&gt; flatMap -&gt; Stream&lt;String&gt;Stream&lt;Set&lt;String&gt;&gt; -&gt; flatMap -&gt; Stream&lt;String&gt;Stream&lt;List&lt;String&gt;&gt; -&gt; flatMap -&gt; Stream&lt;String&gt;Stream&lt;List&lt;Object&gt;&gt; -&gt; flatMap -&gt; Stream&lt;Object&gt; flapMap将这样的input Stream连接成一个新的Stream，实现了底层数据的扁平化处理，其操作过程如下图所示： 12345678Stream&lt;List&lt;Integer&gt;&gt; inputStream = Stream.of( Arrays.asList(1), Arrays.asList(2, 3), Arrays.asList(4, 5, 6));Stream&lt;Integer&gt; outputStream = inputStream. flatMap((childList) -&gt; childList.stream());List&lt;Integer&gt; collected = outputStream.collect(Collectors.toList()); 上面的代码使用Strem的工厂方法，将每一个列表转换为Stream对象，然后使用flatMap方法将多个Stream转换为一个新的Stream。注意flapMap方法的相关函数接口和map方法一样，都是Function接口类型，只是方法的返回值限制为Stream类型罢了。 3.2.4 filterfilter 对原始 Stream 进行某项测试，通过测试的元素被留下来生成一个新 Stream。filter接受的参数是一个Predicate类型的lambda表达式。 下面是用filter保留偶数的操作： 1234Integer[] sixNums = &#123;1, 2, 3, 4, 5, 6&#125;;Integer[] evens = Stream.of(sixNums) .filter(n -&gt; n%2 == 0) .toArray(Integer[]::new); 3.2.5 findFirst这是一个 termimal 兼 short-circuiting 操作，它总是返回 Stream 的第一个元素，或者空。需要注意的是findFirst返回值的类型是Optional，Optional表示一个值的容器，它可能含有某值，可能不包含，使用它的目的是尽可能避免NullPointException。 Stream 中的 findAny、max/min、reduce 等方法等返回 Optional 值。还有例如 IntStream.average() 返回 OptionalDouble 等等。 3.3 使用收集器收集器是将流生成对应集合元素类型的方法，常用的收集器可从java.util.stream.Collectors中导入。例如Collectors.toList()就是一种从流生成对应列表的收集器，通过将收集器传递给collect方法，所有的流就可以使用它了。下面是使用收集器将流转化为其它类型集合的例子： 使用toArray方法将String的流转化为对应的数组 123String[] strArray = Stream.of("a", "b", "c") .filter(x -&gt; x != String.valueOf("b")) .toArray(String[]::new); 注意：toArray接收的函数接口类型或lambda表达式类型是IntFunction，IntFunction如下图所示： 因此，上面的代码和下面的代码是等价的： 123String[] strArray = Stream.of("a", "b", "c") .filter(x -&gt; x != String.valueOf("b")) .toArray(x -&gt; new String[x]); 使用toCollection，用定制的集合收集元素，下面是将Stream收集成TreeSet集合的例子： 123TreeSet&lt;String&gt; strSet = Stream.of("a", "b", "c", "c") .filter(x -&gt; x != String.valueOf("b")) .collect(Collectors.toCollection(TreeSet::new)); 这里，toCollection接收的函授接口类型是Supplier，Supplier表示lambda表达式不接收参数，但返回一个值，由于lambda表达式返回的类型可以根据上下文自动识别，所以这里当然返回的是一个TreeSet的对象了。 参考： Java 8 中的 Streams API 详解 Java8初体验（二）Stream语法详解 Java 8函数式编程]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java 8 新特性：lambda表达式]]></title>
      <url>%2F2016%2F12%2F03%2Fjava-8-%E6%96%B0%E7%89%B9%E6%80%A7%EF%BC%9Alambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[lambda表达式是Java8带给我们的几个重量级特性之一，借用lambda表达式，可以让我们的Java程序设计更加简洁和高效。要深入理解lambda表达式，需要理解函数式接口，lambda表达式的表示形式，以及方法引用。 1. 函数式接口函数式接口是只有一个抽象方法的接口，用作lambda表达式的类型。 函数式接口可以用@FunctionalInterface注解，可以把它放在注解的前面，但它是非必须的，使用注解只是为了方便编译器作语法检查。只要接口只包含一个抽象方法，虚拟机会自动判断。在接口中添加了 @FunctionalInterface 的注解后，该接口就只允许有一个抽象方法，否则编译器也会报错。如下，java.lang.Runnable 就是一个函数式接口： 1234@FunctionalInterfacepublic interface Runnable &#123; public abstract void run();&#125; 函数式接口的重要属性是：我们能够使用 lambda 实例化它们，lambda 表达式让你能够将函数作为方法参数，或者将代码作为数据对待。 2. lambda表达式lambda表达式是一种紧凑的传递行为的方式。lambda表达式由三部分组成：第一部分为一个括号内用逗号分隔的形式参数，参数是函数式接口里面方法的参数；第二部分为一个箭头符号：-&gt;；第三部分为方法体，可以是表达式和代码块。语法如下： 方法体为表达式，该表达式的值作为返回值返回 1(parameters) -&gt; expression 例如： 1Supplier&lt;String&gt; i = ()-&gt; "Supplier test"; 这里，”Supplier test”就是lambda表达式i的get方法返回值。 方法体为代码块，必须用 {} 来包裹起来，且需要一个 return 返回值，但若函数式接口里面方法返回值是 void，则无需返回值。 1(parameters) -&gt; &#123; statements; &#125; 例如上面的例子的等价形式为： 1Supplier&lt;String&gt; i = ()-&gt; &#123;return "Supplier test";&#125;; 下面是匿名内部类的代码： 123456button.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; System.out.print("Hello lambda in actionPerformed"); &#125;&#125;); 下面是使用lambda表达式后的代码： 1234button.addActionListener( //actionPerformed 有一个参数 e 传入，所以用 (ActionEvent e) (ActionEvent e)-&gt; System.out.print("Hello lambda in actionPerformed")); 其实，lambda表达式可以自己根据上下文推断参数类型，无需显示指定： 1button.addActionListener( e -&gt; System.out.print("Hello lambda in actionPerformed")); lambda表达式的几种变体 将lambda表达式赋值给一个一个变量，lambda表达式没有参数： 1Runnable noArguments = () -&gt; System.out.println("Hello World"); //(1) 将lambda表达式赋值给一个一个变量，lambda表达式的参数类型由编译器推导出来： 1ActionListener oneArgument = event -&gt; System.out.println("button clicked"); //(2) 将lambda表达式赋值给一个一个变量，lambda表达式有多个参数类型，参数类型由编译器推导出来： 1BinaryOperator&lt;Long&gt; add = (x, y) -&gt; x + y; //(3) 将lambda表达式赋值给一个一个变量，lambda表达式有多个参数类型，显示声明lambda表达式类型： 1BinaryOperator&lt;Long&gt; addExplicit = (Long x, Long y) -&gt; x + y; //(4) 如上所示，有lambda表达式中的参数类型都是由编译器推断得出的。这当然不错，但有时最好也可以显式声明参数类型，此时就需要使用小括号将参数括起来，多个参数的情况也是如此,如(4)。 注意： 目标类型是指lambda表达式所在上下文环境的类型。比如，将lambda表达式赋值给一个局部变量，或传递给一个方法作为参数，局部变量或方法参数的类型就是lambda表达式的目标类型。lambda表达式的目标类型类型依赖于上下文环境，是由编译器推断出来的。如(1)和(2)的lambda表达式的目标类型分别是Runnable和ActionListener类型，可以把lambda表达式看作实现了该接口的内部类的实例，noArguments和oneArgument分表表示指向实例的引用。 lambda表达式能引用表达式之外定义的既成事实的final变量。虽然无需将变量声明为final，但在lambda表达式中，也无法用作非终态变量。下面的可以编译通过： 12String name = getUserName();button.addActionListener(event -&gt; System.out.println("hi" + name)); 但下面不能编译通过： 123String name = getUserName();name = formatUserName(name);button.addActionListener(event -&gt; System.out.println("hi" + name)); 也就是说，lambda只能引用表达式之外不会改变的变量，之所以有这样的限制，是因为若变量可以改变，并发执行多个lambda表达式时就会不安全。 3. 方法引用可以用已经定义好的类中的方法来表示一个lambda表达式。例如：1button.addActionListener(event -&gt; System.out.println(event)); 可以使用System.out::println的方法引用表示成如下形式：1button.addActionListener(System.out::println); 总的来说，方法引用有如下四种使用情况： 对象::实例方法 类::静态方法 类::实例方法 类::new 在前两种情况，方法引用等同于提供方法参数的lambda表达式。如System.out::println等同于x -&gt; System.out.println(x)。类似的，Math::pow等同于(x, y) -&gt; Math.pow(x, y)。 第三种情况，第一个参数为执行方法的对象，即当lambda表达式的的第一个参数是要执行的方法体所属的对象时，可以使用类::实例方法的方法引用代替。例如：String::compareToIgnoreCase等同于(x, y) -&gt; x.compareToIgnoreCase(y)，这里x就是compareToIgnoreCase方法所属对象。其实这也是合理的，因为Java中实例方法拥有者为一个具体的对象，只有一个对象才能调用实例方法。 下面是一个具体的引用类::实例方法的例子，其中personList.stream().forEach(x -&gt; x.getName())和personList.stream().forEach(Person::getName)是等价的。 1234567891011121314151617181920212223242526import java.util.ArrayList;import java.util.List;public class Main &#123; public static void main(String[] args) &#123; String[] stringArray = &#123; "Barbara", "James", "Mary", "John", "Patricia", "Robert", "Michael", "Linda" &#125;; //Arrays.sort(stringArray, String::compareToIgnoreCase); List&lt;Person&gt; personList = new ArrayList&lt;&gt;(); for( String str : stringArray ) personList.add(new Person(str)); //personList.stream().forEach(x -&gt; x.getName()); personList.stream().forEach(Person::getName); &#125;&#125;class Person &#123; private String name; public Person(String name) &#123; this.name = name; &#125; public String getName() &#123; System.out.println(name); return name; &#125;&#125; 第四种情况则是构造器的引用，对于拥有多个构造器的类，选择使用哪个引用取决于上下文。需要注意的是，虽然方法引用使用的是一个方法，但不需要在后面加括号，因为这里并不调用该方法。使用该方法只是提供了一种和lambda表达式等价的一种结构，在需要时才会调用。凡是使用lambda表达式的地方，就可以使用方法引用。 方法引用还可以使用this或super参数，表示引用本类或父类中的方法，例如：this::equals就等同于x -&gt; this.equals(x)。 123456789101112public class ConcurrentGreeter extends Greeter &#123; public void greet () &#123; Thread t = new Thread(super::greet); t.start(); &#125;&#125;class Greeter &#123; public void greet() &#123; System.out.println("Hello, world"); &#125;&#125; 该例子中，相当于引用父类的方法，实现了一个这样的lambda表达式，返回类型为Runnable：1Thread t = new Thread(() -&gt; System.out.println("Hello, world")); 4. 什么时候使用Lambda表达式函数式接口是lambda表达式的类型，因此，若函数的形参传递的是一个函数式接口类型的引用，则可以直接给该形参传递lambda表达式。当然，也可以给该形参传递实现该接口的匿名类对象或实例。下面的三种方法是等效的，当然，使用lambda表达式是最简洁的。 1234567891011121314151617181920212223import java.util.Arrays;import java.util.function.Consumer;public class Test &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = Arrays.asList("bay", "max", "huang"); list.forEach(new Consumer&lt;String&gt;() &#123; @Override public void accept(String s) &#123; System.out.println(s); &#125; &#125;); // 1: object of an anonymous class list.forEach(new InternalConsumer()); // 2: normal object list.forEach(System.out::println); // 3: lambda &#125; private static class InternalConsumer implements Consumer&lt;String&gt; &#123; @Override public void accept(String s) &#123; System.out.println(s); &#125; &#125;&#125; 参考： Method References Java Lambda Introduction Java 8函数式编程]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ubuntu 下通过apt-get安装JDK和Java IDE]]></title>
      <url>%2F2016%2F12%2F02%2FUbuntu-%E4%B8%8B%E9%80%9A%E8%BF%87apt-get%E5%AE%89%E8%A3%85JDK%E5%92%8CJava-IDE%2F</url>
      <content type="text"><![CDATA[在Linux系统下做Java开发，安装JDK和Java IDE（如eclipse，idea）是必不可少的步骤。网上也有很多关于JDK配置的教程，但任然比较麻烦。下面将介绍在Ubuntu系统下使用在线包管理器apt-get快速安装JDK，eclipse和idea的方法。 1. 安装JDK 安装OpenJDK 123sudo apt-get updatesudo apt-get install default-jresudo apt-get install default-jdk 安装Oracle JDK 12345sudo apt-get install software-properties-common -ysudo add-apt-repository ppa:webupd8team/javasudo apt-get updatesudo apt-get install oracle-java7-installersudo apt-get install oracle-java7-set-default #安装自动设置java 7环境变量的包 选择JDK版本 12sudo update-alternatives --config javasudo update-alternatives --config javac 上述命令会输出当前系统已安装的JDK版本和编号等信息，输入编号信息选择要使用的JDK版本，要维持当前值[*]按回车键。 查看JDK版本 12java -versionjavac -version 2. 安装eclipse 添加ppa源 12sudo apt-add-repository ppa:mmk2410/eclipse-ide-javasudo apt-get update 查看eclipse版本 1sudo apt-cache show eclipse-ide-java 安装eclipse IDE 1sudo apt-get install eclipse-ide-java 启动eclipse 1eclipse-ide 注意：若安装了多个版本的eclipse，也可以通过 update-alternatives 选择指定的版本。 3. 安装Pydev等插件一般高版本的eclipse java IDE自带Pydev插件，若某些版本的IDE没有带pydev插件，则需要手动安装。在线安装较缓慢，网上也有很多教程，下面介绍离线安装pydev插件的方法。 首先在sourceforge下载对应的pydev插件版本，然后解压.zip文件，将features和plugins里的文件拷贝到eclipse安装目录下的对应文件夹里即可。linux系统下eclipse的features和plugins文件夹在/usr/lib/eclipse目录下。 3. 安装idea社区版idea社区版也可以通过apt-get在线安装，和eclipse类似，首先添加ppa软件源： 12sudo add-apt-repository ppa:mmk2410/intellij-idea-communitysudo apt-get update 然后使用apt-get就可以安装了。 4. 总结ppa是Ubuntu Launchpad网站提供的一项服务，允许个人用户作为apt源供其他用户下载和更新，通常比Ubuntu中心提前出来，版本更新，满足大家及时的更新使用。当自己需要添加较新的apt源时，可到launchpad搜索，并通过apt-add-repository命令添加ppa源。 ppa是linux发行版Debian系列的个人软件仓库，类似的还有RedHat系列的epel仓库。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[PXE服务和Cisco路由器上的DHCP配置]]></title>
      <url>%2F2016%2F12%2F01%2FPXE%E6%9C%8D%E5%8A%A1%E5%92%8CCisco%E8%B7%AF%E7%94%B1%E5%99%A8%E4%B8%8A%E7%9A%84DHCP%E9%85%8D%E7%BD%AE%2F</url>
      <content type="text"><![CDATA[预启动执行环境（Preboot eXecution Environment，PXE，也被称为预执行环境）提供了一种使用网络接口（Network Interface）启动计算机的机制，这种机制让计算机的启动可以不依赖本地数据存储设备（如硬盘）或本地已安装的操作系统。 PXE及其协议概述PXE当初是作为Intel的有线管理体系的一部分，Intel 和 Systemsoft于1999年9月20日公布其规格(版本2.1)。通过使用像网际协议(IP)、用户数据报协议(UDP)、动态主机设定协定(DHCP)、小型文件传输协议(TFTP)等几种网络协议和全局唯一标识符(GUID)、通用网络驱动接口(UNDI)、通用唯一识别码(UUID)的概念并通过对客户机(通过PXE自检的电脑)固件扩展预设的API来实现目的。 PXE 协议大致上结合了DHCP和TFTP，虽然都有在两者上面有改进。DHCP用于查找合适的启动服务器,TFTP用于下载初始引导程序和附加文件。为了开始一个PXE自检会话，PXE固件广播一个带有明确的PXE选项DHCPDISCOVER包(扩展DHCPDISCOVER)到67/UDP端口(DHCP服务器端口)。PXE选项是PXE固件有PXE能力的鉴定，但是会被一般的DHCP服务忽略。当固件受到从这样的服务受到DHCPOFFER包时，它会通过要求其提供配置信息来自我配置。 搭建PXE网络启动的服务当经常需要系统恢复或系统安装时，搭建PXE网络启动服务是一个不错的选择。如何搭建PXE网络服务，在这里就不详细赘述，具体参考： Setting up a server for PXE network booting RHEL/CentOS 7 中配置 PXE 网络启动服务器 实际上，PXE网络启动服务就是DHCP服务器给客户系统分配IP地址以及客户系统通过TFTP获取服务器上的镜像文件的过程。因此，建立好TFTP服务后，DHCP服务器还要告知无盘启动的系统TFTP服务器的IP地址和镜像文件的名称。 DHCP作为引导启动协议bootp的升级版，仍然兼容boop协议，而bootp协议在设计之初就是为了使无盘启动的系统分配到ip并获得tftp服务器的镜像文件。bootp协议包的next-server和filename字段就是告知客户系统TFTP镜像服务的地址和镜像名称的过程。 Cisco路由器上PXE网络启动的DHCP配置当前小编的公网环境已经支持PXE网络启动，只是小编的网络是一段使用了NAPT的内网，IP地址由Cisco路由器DHCP分配。因此，若要使用公网的PXE服务，需要在本地的DHCP服务器上引导PXE服务的镜像和地址。下面是Cisco路由器的相关配置：12345ip dhcp pool vlan-namenetwork net-address netmaskbootfile filenamenext-server tftp-addressdefault-router gateaway 用wireshark抓DHCP Reply的包，就会发现next-server和bootfile相关字段的内容。 Troubleshooting 使用PXE启动时，发现有些设备会出现这样的错误：”PXE-E51 No DHCP or proxy DHCP offers were found or received” or “No proxy DHCP offers”，而使用笔记本连接在该设备所在的端口下时，能够正常启动。 这是因为一些网卡直到 MAC 层软件驱动被实际加载之后才会启动链路，而交换设备为了避免环路运行了STP协议，一个正常的交换接口从down到up要经过：Down，listening，learning，fowarding几个状态，一共耗时为30~50秒，从而决定此端口是blocking还是fowarding的，也是交换机的防止环路的机制。因此在dhcp过程中会出现超时现象。 解决这个问题的办法是将连接host的交换机端口设置为portfast状态，使得链路up时交换机端口直接进入forwarding状态，从而避免超时。基本配置方法如下：1Sw1(config)#spanning-tree portfast default %（所有接口启用）全局下用 一般用在接入层的交换机上。12Sw1(config-if)#spanning-tree portfast %单独启用特定接口Sw1(config-if)#spanning-tree portfast disable %（某个端口禁用，通常是连接另一台交换机的端口） 关于portfast的详细信息参考如下连接： 思科交换机Portfast和Uplinkfast配置 Configuring Spanning Tree PortFast, BPDU Guard, BPDU Filter, UplinkFast, BackboneFast, and Loop Guard]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux查看硬件设备信息]]></title>
      <url>%2F2016%2F11%2F25%2FLinux%E6%9F%A5%E7%9C%8B%E7%A1%AC%E4%BB%B6%E8%AE%BE%E5%A4%87%E4%BF%A1%E6%81%AF%2F</url>
      <content type="text"><![CDATA[硬件信息的查询和系统的内核和驱动相关，下面是在Linux系统下常用的查看硬件设备信息的方法。 PCI介绍 PCI是Peripheral Component Interconnect(外设部件互连标准)的缩写，它是目前个人电脑中使用最为广泛的接口，几乎所有的主板产品上都带有这种插槽。PCI插槽也是主板带有最多数量的插槽类型，在目前流行的台式机主板上，ATX结构的主板一般带有5～6个PCI插槽，而小一点的MATX主板也都带有2～3个PCI插槽，可见其应用的广泛性。 lspci lspci列出所有连接到 PCI 总线的详细信息，例如：显卡、网卡、USB 接口及 SATA 控制器等设备，该命令检查硬件设备不依赖于系统是否安装有该硬件对应的驱动模块。 http://superuser.com/questions/165733/will-lsusb-and-lspci-list-devices-for-which-the-system-has-no-drivers 常用的命令有： 1lspci -v 结合lspci和/sys可以查询硬件使用的驱动信息。 12345$lspci...02:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8111/8168B PCI Express Gigabit Ethernet controller (rev 01)$ find /sys | grep drivers.*02:00/sys/bus/pci/drivers/r8169/0000:02:00.0 可以看出使用的以太网卡的驱动是r8169。 http://unix.stackexchange.com/questions/41817/linux-how-to-find-the-device-driver-used-for-a-device dmidecode dmidecode，读取DMI表中的数据来提取硬件信息，可查看bios，cpu，memory等信息 如sudo dmidecode -t memory可查看设备可支持的最大物理内存，当前内存大小，设备内存插槽个数及使用情况等。类似查看硬件信息的命令还有lshw： 1sudo lshw -C net lscpu 列出cpu信息，如： 12345678910111213141516171819202122[optnetlab@ustc ~]$ lscpuArchitecture: x86_64 #cpu构架CPU op-mode(s): 32-bit, 64-bit #支持的操作系统 Byte Order: Little EndianCPU(s): 4 #逻辑CPU个数On-line CPU(s) list: 0-3 #可使用的逻辑CPUThread(s) per core: 2 #每个核的线程数Core(s) per socket: 2 #每个cpu插槽核数/每颗物理cpu核数是2Socket(s): 1 #CPU插槽个数NUMA node(s): 1Vendor ID: GenuineIntelCPU family: 6Model: 42Stepping: 7CPU MHz: 1600.000 #CPU主频BogoMIPS: 6584.65Virtualization: VT-x #CPU支持虚拟化L1d cache: 32K #L1缓存L1i cache: 32KL2 cache: 256KL3 cache: 3072KNUMA node0 CPU(s): 0-3 类似的还有lsusb fdisk和df fdisk和df分别用来查看磁盘分区和文件系统的信息。 12fdisk -ldf -hT 其它常用命令 查看系统物理内存及交换分区信息: 1free -h 查看cpu或memory信息： 12cat /proc/cpuinfcat /proc/meminf]]></content>
    </entry>

    
  
  
</search>
